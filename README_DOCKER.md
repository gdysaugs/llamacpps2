# ğŸ­ SoVITS-Wav2Lip-LlamaCPPçµ±åˆã‚·ã‚¹ãƒ†ãƒ  Dockerç‰ˆ

**AIéŸ³å£°åˆæˆãƒ»ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ»é¡”äº¤æ›ãƒ»AIä¼šè©±** å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ  - Dockerç‰ˆã‚¬ã‚¤ãƒ‰

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### å¿…è¦è¦ä»¶
- **Docker** (20.10+)
- **NVIDIA Docker Runtime** (nvidia-docker2)
- **NVIDIA GPU** (RTX 3060ä»¥ä¸Šæ¨å¥¨)
- **GPU ãƒ¡ãƒ¢ãƒª**: 8GBä»¥ä¸Š
- **ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡**: 50GBä»¥ä¸Š

### 1. å‰æã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# NVIDIA Docker Runtimeã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (Ubuntu/WSL2)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### 2. ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd /home/adama/wav2lip-project

# Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ï¼ˆ20-30åˆ†ï¼‰
docker build -f Dockerfile.gcr-integrated -t wav2lip-gpu-models:latest .
```

### 3. ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•

```bash
# GPUã‚µãƒãƒ¼ãƒˆä»˜ãã§ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
docker run --gpus all -p 8080:8080 -d wav2lip-gpu-models:latest

# ã¾ãŸã¯ã€åå‰ä»˜ãã§èµ·å‹•
docker run --gpus all -p 8080:8080 --name wav2lip-container -d wav2lip-gpu-models:latest
```

### 4. ã‚¢ã‚¯ã‚»ã‚¹

- **ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ã‚¯ã‚»ã‚¹**: http://localhost:8080
- **WSL2**: http://localhost:8080 ï¼ˆWindowsãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ï¼‰

## ğŸ”§ Dockerç®¡ç†ã‚³ãƒãƒ³ãƒ‰

### ã‚³ãƒ³ãƒ†ãƒŠæ“ä½œ
```bash
# å®Ÿè¡Œä¸­ã‚³ãƒ³ãƒ†ãƒŠç¢ºèª
docker ps

# ã‚³ãƒ³ãƒ†ãƒŠåœæ­¢
docker stop wav2lip-container

# ã‚³ãƒ³ãƒ†ãƒŠå‰Šé™¤
docker rm wav2lip-container

# ã‚³ãƒ³ãƒ†ãƒŠãƒ­ã‚°ç¢ºèª
docker logs wav2lip-container

# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã‚·ã‚§ãƒ«å®Ÿè¡Œ
docker exec -it wav2lip-container bash
```

### ã‚¤ãƒ¡ãƒ¼ã‚¸ç®¡ç†
```bash
# ã‚¤ãƒ¡ãƒ¼ã‚¸ä¸€è¦§
docker images | grep wav2lip

# å¤ã„ã‚¤ãƒ¡ãƒ¼ã‚¸å‰Šé™¤
docker rmi wav2lip-gpu-models:latest

# ã‚¤ãƒ¡ãƒ¼ã‚¸å†ãƒ“ãƒ«ãƒ‰ï¼ˆå¼·åˆ¶ï¼‰
docker build --no-cache -f Dockerfile.gcr-integrated -t wav2lip-gpu-models:latest .
```

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

1. **ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™**
   - å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« (MP4, AVI, MOVå¯¾å¿œ)
   - ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£° (WAV, MP3å¯¾å¿œ)
   - ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆ

2. **å‡¦ç†å®Ÿè¡Œ**
   - Phase 1: SoVITSéŸ³å£°ç”Ÿæˆ
   - Phase 2: Wav2Lipãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
   - Phase 3: FaceFusioné¡”äº¤æ›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

3. **çµæœç¢ºèª**
   - ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
   - ãƒ­ã‚°ã§å‡¦ç†è©³ç´°ç¢ºèª

### AIä¼šè©±ãƒ¢ãƒ¼ãƒ‰

```
âœ… AIä¼šè©±ãƒ¢ãƒ¼ãƒ‰ ON
â””â”€â”€ LlamaCPP (Berghof-NSFW-7B) ãŒå¿œç­”ç”Ÿæˆ
â””â”€â”€ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç‰¹å¾´ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´å¯èƒ½
â””â”€â”€ è‡ªç„¶ãªæ—¥æœ¬èªã§ã®å¯¾è©±
```

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. SoVITSãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `FileNotFoundError: GPT_SoVITS/pretrained_models/gsv-v4-pretrained/s2Gv4.pth`

**åŸå› **: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ãŒå£Šã‚Œã¦ã„ã‚‹

**è§£æ±ºæ–¹æ³•**:
```bash
# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ãƒ‘ã‚¹ä¿®æ­£
docker exec -it <CONTAINER_ID> bash

# s2Gv4.pthãƒªãƒ³ã‚¯ä½œæˆ
ln -sf /app/gpt_sovits_full/GPT_SoVITS/pretrained_models/s2Gv4.pth \
       /app/GPT_SoVITS/pretrained_models/gsv-v4-pretrained/s2Gv4.pth

# vocoder.pthãƒªãƒ³ã‚¯ä¿®æ­£
rm -f /app/GPT_SoVITS/pretrained_models/gsv-v4-pretrained/vocoder.pth
ln -sf /app/gpt_sovits_full/GPT_SoVITS/pretrained_models/gpt_sovits_models_vocoder.pth \
       /app/GPT_SoVITS/pretrained_models/gsv-v4-pretrained/vocoder.pth

# ã‚³ãƒ³ãƒ†ãƒŠå†èµ·å‹•
exit
docker restart <CONTAINER_ID>
```

### 2. ãƒãƒ¼ãƒˆç«¶åˆã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `port is already allocated`

**è§£æ±ºæ–¹æ³•**:
```bash
# åˆ¥ã®ãƒãƒ¼ãƒˆã§èµ·å‹•
docker run --gpus all -p 8081:8080 -d wav2lip-gpu-models:latest

# ã¾ãŸã¯æ—¢å­˜ã‚³ãƒ³ãƒ†ãƒŠåœæ­¢
docker ps | grep wav2lip
docker stop <CONTAINER_ID>
```

### 3. GPUèªè­˜ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `RuntimeError: No CUDA GPUs are available`

**è§£æ±ºæ–¹æ³•**:
```bash
# NVIDIA Docker Runtimeç¢ºèª
nvidia-smi
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# CPUãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ï¼ˆéæ¨å¥¨ï¼‰
docker run -p 8080:8080 -e CUDA_VISIBLE_DEVICES="" -d wav2lip-gpu-models:latest
```

### 4. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `CUDA out of memory`

**è§£æ±ºæ–¹æ³•**:
```bash
# GPU ãƒ¡ãƒ¢ãƒªåˆ¶é™è¨­å®š
docker run --gpus all --memory=16g --memory-swap=32g \
  -p 8080:8080 -d wav2lip-gpu-models:latest

# å‡¦ç†å‰ã«GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
docker exec <CONTAINER_ID> python -c "import torch; torch.cuda.empty_cache()"
```

### 5. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸è¶³

**ç—‡çŠ¶**: å„ç¨® `FileNotFoundError`

**è§£æ±ºæ–¹æ³•**:
```bash
# ã‚³ãƒ³ãƒ†ãƒŠå†…ãƒ¢ãƒ‡ãƒ«ç¢ºèª
docker exec <CONTAINER_ID> find /app -name "*.pth" -o -name "*.ckpt" -o -name "*.gguf"

# ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯å†ãƒ“ãƒ«ãƒ‰
docker build --no-cache -f Dockerfile.gcr-integrated -t wav2lip-gpu-models:latest .
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´

### æœ€é©åŒ–è¨­å®š

```bash
# é«˜æ€§èƒ½GPU (RTX 4090ç­‰)
docker run --gpus all -p 8080:8080 \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024 \
  -d wav2lip-gpu-models:latest

# ä½ãƒ¡ãƒ¢ãƒªGPU (RTX 3060ç­‰)
docker run --gpus all -p 8080:8080 \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256 \
  -d wav2lip-gpu-models:latest
```

### å‡¦ç†æ™‚é–“ç›®å®‰

| GPU | Phase 1 (SoVITS) | Phase 2 (Wav2Lip) | åˆè¨ˆ |
|-----|-------------------|-------------------|------|
| RTX 4090 | 15-30ç§’ | 30-60ç§’ | 1-2åˆ† |
| RTX 3080 | 30-45ç§’ | 60-90ç§’ | 2-3åˆ† |
| RTX 3060 | 45-60ç§’ | 90-120ç§’ | 3-4åˆ† |

## ğŸ” ãƒ­ã‚°è§£æ

### ã‚³ãƒ³ãƒ†ãƒŠãƒ­ã‚°ç¢ºèª
```bash
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°
docker logs -f <CONTAINER_ID>

# æœ€æ–°100è¡Œ
docker logs --tail 100 <CONTAINER_ID>

# ã‚¨ãƒ©ãƒ¼ã®ã¿æŠ½å‡º
docker logs <CONTAINER_ID> 2>&1 | grep -i error
```

### å‡¦ç†ãƒ­ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³
```
âœ… æ­£å¸¸èµ·å‹•:
ğŸ­ğŸ¬ğŸ¤– SOVITS-Wav2Lip-LlamaCPP Integration System
âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†
ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹URL: http://0.0.0.0:8080

âœ… æ­£å¸¸å‡¦ç†:
ğŸš€ ãƒãƒ¼ã‚¿ãƒ–ãƒ«ç‰ˆçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹
ğŸµ Phase 1: SoVITSéŸ³å£°ç”Ÿæˆé–‹å§‹
âœ… Phase 1å®Œäº†: /app/output/temp_*.wav
ğŸ¬ Phase 2: Wav2Lip ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹
âœ… Phase 2å®Œäº†: /app/temp/temp_*.mp4

âŒ ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³:
âŒ Phase 1å¤±æ•—: âŒ SOVITS Voice Cloning Failed
ğŸ” Error reason: Process failed with return code 1
```

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ï¼ˆDockerç‰ˆï¼‰

```
/app/ (ã‚³ãƒ³ãƒ†ãƒŠå†…)
â”œâ”€â”€ gpt_sovits_full/          # GPT-SoVITSãƒ•ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³
â”‚   â””â”€â”€ GPT_SoVITS/
â”‚       â””â”€â”€ pretrained_models/
â”‚           â”œâ”€â”€ s2Gv4.pth         # VITSãƒ¢ãƒ‡ãƒ« (769MB)
â”‚           â”œâ”€â”€ gpt_sovits_models_vocoder.pth # Vocoder (57MB)
â”‚           â”œâ”€â”€ chinese-hubert-base/
â”‚           â””â”€â”€ chinese-roberta-wwm-ext-large/
â”œâ”€â”€ models/                    # è¿½åŠ ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ gpt_sovits/
â”‚   â”œâ”€â”€ wav2lip/
â”‚   â””â”€â”€ facefusion/
â”œâ”€â”€ gradio_frontend/           # Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   â”œâ”€â”€ wav2lip_sovits_llama_integrated_portable.py
â”‚   â””â”€â”€ sovits_wav2lip_integration.py
â”œâ”€â”€ checkpoints/               # Wav2Lipãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ output/                    # ç”Ÿæˆçµæœ
â””â”€â”€ temp/                      # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸš§ é–‹ç™ºãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ«ãƒ‰
```bash
# é–‹ç™ºç”¨ãƒã‚¦ãƒ³ãƒˆèµ·å‹•
docker run --gpus all -p 8080:8080 \
  -v $(pwd)/gradio_frontend:/app/gradio_frontend:ro \
  -d wav2lip-gpu-models:latest

# ã‚³ãƒ¼ãƒ‰ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰
docker exec <CONTAINER_ID> pkill -f "wav2lip_sovits_llama_integrated_portable.py"
```

### ç’°å¢ƒå¤‰æ•°è¨­å®š
```bash
# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§èµ·å‹•
docker run --gpus all -p 8080:8080 \
  -e CUDA_VISIBLE_DEVICES=0 \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \
  -e GRADIO_SERVER_NAME=0.0.0.0 \
  -e GRADIO_SERVER_PORT=8080 \
  -d wav2lip-gpu-models:latest
```

## âš ï¸ æ³¨æ„äº‹é …

- **GPUå¿…é ˆ**: CPU-onlyãƒ¢ãƒ¼ãƒ‰ã¯å®Ÿç”¨çš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“
- **VRAM**: æœ€ä½8GBã€æ¨å¥¨12GBä»¥ä¸Š
- **å‡¦ç†æ™‚é–“**: 1åˆ†ã®å‹•ç”»ã§3-5åˆ†ã®å‡¦ç†æ™‚é–“
- **å“è³ª**: é«˜å“è³ªãƒ¢ãƒ¼ãƒ‰ã¯å‡¦ç†æ™‚é–“ãŒ2-3å€
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: åˆå›ãƒ“ãƒ«ãƒ‰æ™‚ã«å¤§é‡ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

### ãƒ­ã‚°æå‡ºæ™‚ã®æƒ…å ±
```bash
# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
nvidia-smi
docker --version
docker info | grep -i runtime

# ã‚³ãƒ³ãƒ†ãƒŠæƒ…å ±
docker inspect <CONTAINER_ID>
docker logs --tail 200 <CONTAINER_ID>
```

---

**æœ€çµ‚æ›´æ–°**: 2025-09-26
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0-docker (Dockerçµ±åˆç‰ˆ)
**ä½œæˆè€…**: Claude Code Assistant