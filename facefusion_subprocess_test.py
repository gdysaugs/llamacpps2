#!/usr/bin/env python3
"""
FaceFusion ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
æ—¢å­˜ã®CLIãƒ†ã‚¹ãƒˆã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹åŒ–
"""
import subprocess
import time
import psutil
import torch
import os

def get_memory_info():
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—"""
    memory = psutil.virtual_memory()
    gpu_info = {}
    
    if torch.cuda.is_available():
        gpu_info = {
            'allocated': torch.cuda.memory_allocated() / 1024**2,
            'reserved': torch.cuda.memory_reserved() / 1024**2
        }
    
    return {
        'cpu_percent': memory.percent,
        'cpu_used_gb': memory.used / 1024**3,
        'gpu': gpu_info
    }

def run_cli_test_subprocess():
    """CLI ãƒ†ã‚¹ãƒˆã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œ"""
    print("ğŸš€ FaceFusion CLIãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ï¼‰é–‹å§‹")
    
    # é–‹å§‹å‰ãƒ¡ãƒ¢ãƒª
    mem_before = get_memory_info()
    print(f"é–‹å§‹å‰: CPU={mem_before['cpu_percent']:.1f}%, GPU={mem_before['gpu'].get('allocated', 0):.1f}MB")
    
    start_time = time.time()
    
    try:
        # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§CLIãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        result = subprocess.run(
            ['python', 'facefusion_cli_test.py'],
            capture_output=True,
            text=True,
            timeout=120,  # 2åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            cwd='/home/adama/wav2lip-project'
        )
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"å®Ÿè¡Œæ™‚é–“: {processing_time:.1f}ç§’")
        print(f"çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}")
        
        # çµæœè¡¨ç¤º
        if result.stdout:
            print("æ¨™æº–å‡ºåŠ›:")
            print(result.stdout[-500:])  # æœ€å¾Œã®500æ–‡å­—
            
        if result.stderr and result.returncode != 0:
            print("ã‚¨ãƒ©ãƒ¼å‡ºåŠ›:")
            print(result.stderr[-300:])
        
        success = result.returncode == 0
        
    except subprocess.TimeoutExpired:
        print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        success = False
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        success = False
    
    # å®Œäº†å¾Œãƒ¡ãƒ¢ãƒª
    time.sleep(1)
    mem_after = get_memory_info()
    print(f"å®Œäº†å¾Œ: CPU={mem_after['cpu_percent']:.1f}%, GPU={mem_after['gpu'].get('allocated', 0):.1f}MB")
    
    # ãƒ¡ãƒ¢ãƒªå¤‰åŒ–
    cpu_diff = mem_after['cpu_percent'] - mem_before['cpu_percent']
    gpu_diff = mem_after['gpu'].get('allocated', 0) - mem_before['gpu'].get('allocated', 0)
    print(f"å¤‰åŒ–: CPU={cpu_diff:+.1f}%, GPU={gpu_diff:+.1f}MB")
    
    return success

def test_multiple_runs(count=3):
    """è¤‡æ•°å›å®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ”„ {count}å›é€£ç¶šå®Ÿè¡Œãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    results = []
    for i in range(count):
        print(f"\n--- å®Ÿè¡Œ {i+1}/{count} ---")
        
        success = run_cli_test_subprocess()
        results.append(success)
        
        if i < count - 1:  # æœ€å¾Œä»¥å¤–ã¯å¾…æ©Ÿ
            time.sleep(3)
    
    # çµæœã‚µãƒãƒªãƒ¼
    success_count = sum(results)
    print(f"\nğŸ“Š çµæœ: {success_count}/{count} æˆåŠŸ")
    
    if success_count == count:
        print("âœ… å…¨ã¦æˆåŠŸ - ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å‹•ä½œå®‰å®š")
    else:
        print("âš ï¸ ä¸€éƒ¨å¤±æ•— - èª¿æŸ»ãŒå¿…è¦")
    
    return success_count == count

def main():
    print("ğŸ§ª FaceFusion ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆé«˜é€Ÿç‰ˆï¼‰")
    print("=" * 50)
    
    # 1å›å®Ÿè¡Œãƒ†ã‚¹ãƒˆ
    success = run_cli_test_subprocess()
    
    if success:
        print("âœ… å˜å›å®Ÿè¡ŒæˆåŠŸ")
        
        # è¤‡æ•°å›å®Ÿè¡Œãƒ†ã‚¹ãƒˆ
        all_success = test_multiple_runs(3)
        
        if all_success:
            print("\nğŸ¯ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ãƒ†ã‚¹ãƒˆå®Œå…¨æˆåŠŸï¼")
            print("âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãªã—")
            print("âœ… ãƒ—ãƒ­ã‚»ã‚¹åˆ†é›¢æ­£å¸¸")
            print("âœ… é€£ç¶šå®Ÿè¡Œå®‰å®š")
        else:
            print("\nâš ï¸ ä¸€éƒ¨ã§å•é¡Œç™ºç”Ÿ")
    else:
        print("âŒ å˜å›å®Ÿè¡Œå¤±æ•—")

if __name__ == "__main__":
    main()