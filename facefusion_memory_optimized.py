#!/usr/bin/env python3
"""
FaceFusion Memory Optimized Direct Execution
é †æ¬¡å‡¦ç† + æ˜ç¤ºçš„ãƒ¡ãƒ¢ãƒªè§£æ”¾
"""

import os
import sys
import time
import gc
import psutil
from pathlib import Path

# FaceFusionã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path("/home/adama/wav2lip-project/facefusion")))

def setup_cuda_environment():
    """CUDAç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š"""
    work_dir = Path("/home/adama/wav2lip-project")
    venv_lib = work_dir / "facefusion_env/lib/python3.10/site-packages"

    cuda_paths = [
        venv_lib / "nvidia/cuda_runtime/lib",
        venv_lib / "nvidia/cudnn/lib",
        venv_lib / "nvidia/cublas/lib",
        venv_lib / "nvidia/cufft/lib"
    ]

    ld_library_path = ":".join(str(p) for p in cuda_paths)
    current_path = os.environ.get("LD_LIBRARY_PATH", "")
    if current_path:
        ld_library_path = f"{ld_library_path}:{current_path}"

    os.environ["LD_LIBRARY_PATH"] = ld_library_path

def get_memory_info():
    """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    gpu_memory = get_gpu_memory()
    return memory_mb, gpu_memory

def get_gpu_memory():
    """GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
    try:
        import torch
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
    except:
        pass
    return 0

def clear_memory():
    """ãƒ¡ãƒ¢ãƒªã‚’æ˜ç¤ºçš„ã«è§£æ”¾"""
    gc.collect()
    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    except:
        pass
    gc.collect()
    print(f"ãƒ¡ãƒ¢ãƒªè§£æ”¾å®Ÿè¡Œæ¸ˆã¿")

def face_swap_process(source_path, target_path, output_path):
    """Face Swapperå‡¦ç†ï¼ˆé–¢æ•°ã‚¹ã‚³ãƒ¼ãƒ—ã§ãƒ¡ãƒ¢ãƒªç®¡ç†ï¼‰"""
    print(f"\n[Step 1/2] Face Swapperå‡¦ç†é–‹å§‹...")
    start_time = time.time()
    mem_before = get_memory_info()
    print(f"é–‹å§‹æ™‚ãƒ¡ãƒ¢ãƒª: RAM {mem_before[0]:.0f}MB, GPU {mem_before[1]:.0f}MB")

    # FaceFusionã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨å®Ÿè¡Œ
    os.chdir("/home/adama/wav2lip-project/facefusion")
    sys.argv = [
        "facefusion.py", "headless-run",
        "--source-paths", str(source_path),
        "--target-path", str(target_path),
        "--output-path", str(output_path),
        "--execution-providers", "cuda",
        "--face-detector-model", "retinaface",
        "--face-detector-size", "320x320",
        "--face-swapper-model", "inswapper_128_fp16",
        "--processors", "face_swapper",
        "--execution-thread-count", "2",
        "--video-memory-strategy", "tolerant",
        "--log-level", "info"
    ]

    import facefusion.core as core
    core.cli()

    elapsed = time.time() - start_time
    mem_after = get_memory_info()
    print(f"âœ… Face Swapperå®Œäº†: {elapsed:.2f}ç§’")
    print(f"çµ‚äº†æ™‚ãƒ¡ãƒ¢ãƒª: RAM {mem_after[0]:.0f}MB, GPU {mem_after[1]:.0f}MB")

    # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
    del core

    return elapsed

def gfpgan_process(input_path, output_path):
    """GFPGAN Enhancementå‡¦ç†ï¼ˆé–¢æ•°ã‚¹ã‚³ãƒ¼ãƒ—ã§ãƒ¡ãƒ¢ãƒªç®¡ç†ï¼‰"""
    print(f"\n[Step 2/2] GFPGAN Enhancementå‡¦ç†é–‹å§‹...")
    start_time = time.time()
    mem_before = get_memory_info()
    print(f"é–‹å§‹æ™‚ãƒ¡ãƒ¢ãƒª: RAM {mem_before[0]:.0f}MB, GPU {mem_before[1]:.0f}MB")

    # FaceFusionã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨å®Ÿè¡Œ
    os.chdir("/home/adama/wav2lip-project/facefusion")
    sys.argv = [
        "facefusion.py", "headless-run",
        "--source-paths", str(input_path),
        "--target-path", str(input_path),
        "--output-path", str(output_path),
        "--execution-providers", "cuda",
        "--processors", "face_enhancer",
        "--face-enhancer-model", "gfpgan_1.4",
        "--face-enhancer-blend", "25",
        "--face-enhancer-weight", "0.5",
        "--execution-thread-count", "2",
        "--video-memory-strategy", "tolerant",
        "--log-level", "info"
    ]

    import facefusion.core as core
    core.cli()

    elapsed = time.time() - start_time
    mem_after = get_memory_info()
    print(f"âœ… GFPGAN Enhancementå®Œäº†: {elapsed:.2f}ç§’")
    print(f"çµ‚äº†æ™‚ãƒ¡ãƒ¢ãƒª: RAM {mem_after[0]:.0f}MB, GPU {mem_after[1]:.0f}MB")

    # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
    del core

    return elapsed

def main():
    print("=" * 60)
    print("FaceFusion Memory Optimized Direct Execution")
    print("é †æ¬¡å‡¦ç† + æ˜ç¤ºçš„ãƒ¡ãƒ¢ãƒªè§£æ”¾")
    print("=" * 60)

    # CUDAç’°å¢ƒè¨­å®š
    setup_cuda_environment()

    # ãƒ‘ã‚¹è¨­å®š
    work_dir = Path("/home/adama/wav2lip-project")
    source_image = work_dir / "input/source_face.jpg"
    target_video = work_dir / "input/target_video_3s.mp4"
    temp_video = work_dir / f"output/facefusion/temp_{int(time.time())}.mp4"
    output_video = work_dir / f"output/facefusion/memory_opt_{int(time.time())}.mp4"

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_video.parent.mkdir(parents=True, exist_ok=True)

    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    if not source_image.exists():
        print(f"âŒ ã‚½ãƒ¼ã‚¹ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_image}")
        return

    if not target_video.exists():
        print(f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_video}")
        return

    print(f"\nå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  ã‚½ãƒ¼ã‚¹: {source_image}")
    print(f"  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {target_video}")
    print(f"  å‡ºåŠ›: {output_video}")

    print(f"\næœ€é©åŒ–è¨­å®š:")
    print("-" * 40)
    print("âœ… é †æ¬¡å‡¦ç†: Face Swap â†’ GFPGAN")
    print("âœ… é–¢æ•°ã‚¹ã‚³ãƒ¼ãƒ—ã§ãƒ¡ãƒ¢ãƒªåˆ†é›¢")
    print("âœ… å„ã‚¹ãƒ†ãƒƒãƒ—å¾Œã«æ˜ç¤ºçš„ãƒ¡ãƒ¢ãƒªè§£æ”¾")
    print("âœ… GPU ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢")
    print("âœ… ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¼·åˆ¶å®Ÿè¡Œ")
    print("-" * 40)

    try:
        total_start = time.time()
        initial_mem = get_memory_info()
        print(f"\nåˆæœŸãƒ¡ãƒ¢ãƒª: RAM {initial_mem[0]:.0f}MB, GPU {initial_mem[1]:.0f}MB")

        # Step 1: Face Swapper (é–¢æ•°å†…ã§å‡¦ç†)
        step1_time = face_swap_process(source_image, target_video, temp_video)
        after_step1 = get_memory_info()

        # Step 2: GFPGAN Enhancement (é–¢æ•°å†…ã§å‡¦ç†)
        step2_time = gfpgan_process(temp_video, output_video)

        # å…¨å‡¦ç†å®Œäº†å¾Œã«ãƒ¡ãƒ¢ãƒªè§£æ”¾
        print("\n--- æœ€çµ‚ãƒ¡ãƒ¢ãƒªè§£æ”¾ä¸­ ---")
        clear_memory()
        after_clear2 = get_memory_info()
        print(f"è§£æ”¾å¾Œãƒ¡ãƒ¢ãƒª: RAM {after_clear2[0]:.0f}MB, GPU {after_clear2[1]:.0f}MB")

        # å…¨ä½“ã®å‡¦ç†æ™‚é–“
        total_time = time.time() - total_start

        print("\n" + "=" * 60)
        print("âœ… å…¨å‡¦ç†å®Œäº†ï¼")
        print(f"Step 1 (Face Swap): {step1_time:.2f}ç§’")
        print(f"Step 2 (GFPGAN): {step2_time:.2f}ç§’")
        print(f"åˆè¨ˆå‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚µãƒãƒªãƒ¼
        print(f"\nãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:")
        print(f"  åˆæœŸ: RAM {initial_mem[0]:.0f}MB")
        print(f"  Step1å¾Œ: RAM {after_step1[0]:.0f}MB")
        print(f"  æœ€çµ‚è§£æ”¾å¾Œ: RAM {after_clear2[0]:.0f}MB")

        # FPSè¨ˆç®—
        fps = 90 / total_time
        print(f"\nå¹³å‡FPS: {fps:.2f}")

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if output_video.exists():
            size_mb = output_video.stat().st_size / (1024 * 1024)
            print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
            print(f"å‡ºåŠ›ãƒ‘ã‚¹: {output_video}")

            # æ¯”è¼ƒ
            print(f"\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ:")
            print(f"ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆ: 160ç§’")
            print(f"ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆ: {total_time:.2f}ç§’")
            if total_time < 160:
                improvement = (160 / total_time - 1) * 100
                print(f"ğŸš€ é€Ÿåº¦æ”¹å–„: +{improvement:.0f}%")

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
            if temp_video.exists():
                temp_video.unlink()
                print(f"\nä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤æ¸ˆã¿")
        else:
            print(f"âŒ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {output_video}")
            print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ®‹ã£ã¦ã„ã¾ã™: {temp_video}")
            if temp_video.exists():
                print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {temp_video.stat().st_size / (1024 * 1024):.2f} MB")

        print("=" * 60)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"\nâŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ä»®æƒ³ç’°å¢ƒãƒã‚§ãƒƒã‚¯
    if not sys.prefix.endswith("facefusion_env"):
        print("âš ï¸ ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„:")
        print("source /home/adama/wav2lip-project/facefusion_env/bin/activate")
        sys.exit(1)

    main()