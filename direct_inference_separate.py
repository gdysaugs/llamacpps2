#!/usr/bin/env python3
"""
GPT-SoVITS å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆâ†’ffmpegçµåˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é•·æ–‡ã‚’çŸ­æ–‡ã«åˆ†å‰²ã—ã¦å€‹åˆ¥wavãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã—ã€ffmpegã§çµåˆ
"""

import os
import sys
import soundfile as sf
import json
import numpy as np
import re
import subprocess
from pathlib import Path

def get_base_path():
    """å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åŸºæº–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    if getattr(sys, 'frozen', False):
        base_path = Path(sys.executable).parent
    else:
        base_path = Path(__file__).parent
    return base_path

def setup_environment():
    """ç’°å¢ƒè¨­å®šã¨ãƒ‘ã‚¹è¨­å®š"""
    base_path = get_base_path()
    gpt_sovits_dir = base_path / "gpt_sovits_full"
    if not gpt_sovits_dir.exists():
        raise FileNotFoundError(f"GPT-SoVITS directory not found: {gpt_sovits_dir}")
    
    os.chdir(str(gpt_sovits_dir))
    sys.path.insert(0, str(gpt_sovits_dir))
    sys.path.insert(0, str(gpt_sovits_dir / "GPT_SoVITS"))
    
    return base_path, gpt_sovits_dir

class SeparateTTS:
    def __init__(self):
        self.base_path, self.gpt_sovits_dir = setup_environment()
        self.config = self.load_config()
        self.tts_pipeline = None
        
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        config_file = self.base_path / "tts_config.json"
        
        default_config = {
            "model_config_path": "gpt_sovits_full/GPT_SoVITS/configs/tts_infer.yaml",
            "ref_audio_path": "models/gpt_sovits/e_01_08_extended.wav", 
            "prompt_text": "",
            "output_dir": "output",
            "chunk_length": 50,
            "tts_params": {
                "top_k": 5,
                "top_p": 1,
                "temperature": 1.5,
                "text_split_method": "cut0",
                "speed_factor": 1.2,
                "batch_size": 4,
                "parallel_infer": True,
                "streaming_mode": False,
                "ref_free": True,
                "seed": 42
            }
        }
        
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                default_config.update(user_config)
            except Exception as e:
                print(f"è­¦å‘Š: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return default_config
    
    def convert_to_wav(self, audio_path):
        """MP3ã‚„ä»–ã®å½¢å¼ã‚’WAVã«è‡ªå‹•å¤‰æ›"""
        import subprocess
        from pathlib import Path

        audio_path = Path(audio_path)

        # æ—¢ã«WAVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if audio_path.suffix.lower() == '.wav':
            return str(audio_path)

        # WAVå¤‰æ›å¾Œã®ãƒ‘ã‚¹
        wav_path = audio_path.with_suffix('.wav')

        # æ—¢ã«å¤‰æ›æ¸ˆã¿ã®WAVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        if wav_path.exists():
            print(f"âœ… å¤‰æ›æ¸ˆã¿WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {wav_path.name}")
            return str(wav_path)

        print(f"ğŸ”„ {audio_path.suffix.upper()}ã‚’WAVã«å¤‰æ›ä¸­: {audio_path.name} -> {wav_path.name}")

        try:
            # ffmpegã§å¤‰æ›
            cmd = [
                'ffmpeg', '-i', str(audio_path),
                '-ar', '22050',  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
                '-ac', '1',      # ãƒ¢ãƒãƒ©ãƒ«
                '-y',            # ä¸Šæ›¸ã
                str(wav_path)
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                print(f"âœ… WAVå¤‰æ›å®Œäº†: {wav_path.name}")
                return str(wav_path)
            else:
                print(f"âŒ WAVå¤‰æ›å¤±æ•—: {result.stderr}")
                return str(audio_path)  # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™

        except Exception as e:
            print(f"âŒ WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return str(audio_path)  # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™

    def extend_short_audio(self, audio_path, min_duration=3.0):
        """çŸ­ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¹°ã‚Šè¿”ã—å»¶é•·ã—ã¦æœ€å°æ™‚é–“ä»¥ä¸Šã«ã™ã‚‹"""
        import soundfile as sf
        import numpy as np
        
        try:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            audio_data, sr = sf.read(audio_path)
            current_duration = len(audio_data) / sr
            
            if current_duration >= min_duration:
                return audio_path  # æ—¢ã«ååˆ†ãªé•·ã•
            
            print(f"ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãŒçŸ­ã„ ({current_duration:.2f}ç§’) -> {min_duration}ç§’ã«å»¶é•·ä¸­...")
            
            # å¿…è¦ãªç¹°ã‚Šè¿”ã—å›æ•°ã‚’è¨ˆç®—
            repeat_count = int(np.ceil(min_duration / current_duration))
            
            # éŸ³å£°ã‚’ç¹°ã‚Šè¿”ã—
            extended_audio = np.tile(audio_data, repeat_count)
            
            # æŒ‡å®šæ™‚é–“ã§ã‚«ãƒƒãƒˆ
            target_samples = int(min_duration * sr)
            extended_audio = extended_audio[:target_samples]
            
            # æ‹¡å¼µç‰ˆã‚’ä¿å­˜
            extended_path = audio_path.replace('.wav', '_extended.wav')
            sf.write(extended_path, extended_audio, sr)
            
            final_duration = len(extended_audio) / sr
            print(f"âœ… éŸ³å£°å»¶é•·å®Œäº†: {final_duration:.2f}ç§’ ({repeat_count}å›ç¹°ã‚Šè¿”ã—)")
            
            return extended_path
            
        except Exception as e:
            print(f"âŒ éŸ³å£°å»¶é•·ã‚¨ãƒ©ãƒ¼: {e}")
            return audio_path  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ‘ã‚¹ã‚’è¿”ã™

    def init_tts(self):
        """TTS ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        from GPT_SoVITS.TTS_infer_pack.TTS import TTS, TTS_Config
        
        # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã®é•·ã•ãƒã‚§ãƒƒã‚¯ãƒ»å»¶é•·
        ref_audio_path_str = self.config["ref_audio_path"]
        # çµ¶å¯¾ãƒ‘ã‚¹ã‹ç›¸å¯¾ãƒ‘ã‚¹ã‹ã‚’åˆ¤å®š
        if Path(ref_audio_path_str).is_absolute():
            ref_audio_path = Path(ref_audio_path_str)
        else:
            ref_audio_path = self.base_path / ref_audio_path_str

        if ref_audio_path.exists():
            extended_ref_path = self.extend_short_audio(str(ref_audio_path))
            # å»¶é•·ã•ã‚ŒãŸãƒ‘ã‚¹ã§è¨­å®šã‚’æ›´æ–°ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ã®ã¾ã¾ä¿æŒï¼‰
            if extended_ref_path != str(ref_audio_path):
                self.config["ref_audio_path"] = extended_ref_path
        
        model_config_path = self.config["model_config_path"]
        if model_config_path.startswith("gpt_sovits_full/"):
            config_path = self.base_path / model_config_path
        else:
            config_path = self.gpt_sovits_dir / model_config_path
            
        if not config_path.exists():
            raise FileNotFoundError(f"Model config not found: {config_path}")
        
        tts_config = TTS_Config(str(config_path))
        self.tts_pipeline = TTS(tts_config)
        print("TTS ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        return self.tts_pipeline
    
    def split_text(self, text, max_length=50):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªåŒºåˆ‡ã‚Šã§åˆ†å‰²"""
        if len(text) <= max_length:
            return [text]

        chunks = []
        current_chunk = ""

        # å¥ç‚¹ãƒ»èª­ç‚¹ãƒ»æ„Ÿå˜†ç¬¦ãƒ»ç–‘å•ç¬¦ã§åˆ†å‰²
        sentences = re.split(r'([ã€‚ã€ï¼ï¼Ÿ])', text)

        for i in range(0, len(sentences), 2):
            if i + 1 < len(sentences):
                sentence = sentences[i] + sentences[i + 1]  # æ–‡ + å¥ç‚¹
            else:
                sentence = sentences[i]

            # ç©ºæ–‡å­—åˆ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if not sentence.strip():
                continue

            if len(current_chunk + sentence) <= max_length:
                current_chunk += sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence

        if current_chunk:
            chunks.append(current_chunk.strip())

        # ã¾ã é•·ã™ãã‚‹å ´åˆã¯å¼·åˆ¶åˆ†å‰²
        final_chunks = []
        for chunk in chunks:
            if len(chunk) <= max_length:
                final_chunks.append(chunk)
            else:
                for i in range(0, len(chunk), max_length):
                    final_chunks.append(chunk[i:i + max_length])

        return final_chunks
    
    def generate_chunk_file(self, text_chunk, chunk_id, temp_dir):
        """1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’è‡ªå‹•çš„ã«WAVã«å¤‰æ›
        ref_audio_path_str = self.config["ref_audio_path"]
        # çµ¶å¯¾ãƒ‘ã‚¹ã‹ç›¸å¯¾ãƒ‘ã‚¹ã‹ã‚’åˆ¤å®š
        if Path(ref_audio_path_str).is_absolute():
            raw_ref_path = Path(ref_audio_path_str)
        else:
            raw_ref_path = self.base_path / ref_audio_path_str

        ref_audio_path = self.convert_to_wav(raw_ref_path)

        # çŸ­ã„éŸ³å£°ã‚’å»¶é•·ï¼ˆã™ã§ã«å»¶é•·æ¸ˆã¿ãªã‚‰ä½¿ç”¨ï¼‰
        if "_extended.wav" not in str(ref_audio_path):
            ref_audio_path = self.extend_short_audio(ref_audio_path)

        # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
        original_text = text_chunk

        # 10æ–‡å­—ä»¥ä¸‹ã®çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã«å›ºå®šéŸ³å£°ã‚’è¿½åŠ ï¼ˆç„¡åŠ¹åŒ–ï¼‰
        padding_added = False
        # if len(text_chunk.strip()) <= 10:
        #     text_chunk = text_chunk + "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"
        #     padding_added = True
        #     print(f"çŸ­æ–‡ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°è¿½åŠ : '{original_text}' â†’ '{text_chunk}'")

        # ã™ã¹ã¦ã®å¥èª­ç‚¹ã‚’èª­ç‚¹ã«å¤‰æ›ï¼ˆREADMEã®æŒ‡ç¤ºé€šã‚Šï¼‰
        text_chunk = text_chunk.replace('ã€‚', 'ã€')
        text_chunk = text_chunk.replace('ï¼', 'ã€')
        text_chunk = text_chunk.replace('ï¼Ÿ', 'ã€')
        text_chunk = text_chunk.replace('.', 'ã€')
        text_chunk = text_chunk.replace('!', 'ã€')
        text_chunk = text_chunk.replace('?', 'ã€')

        request = {
            "text": text_chunk,
            "text_lang": "ja",
            "ref_audio_path": str(ref_audio_path),
            "prompt_text": self.config.get("prompt_text", ""),
            "prompt_lang": "ja",
            "return_fragment": False,
            **self.config["tts_params"]
        }

        print(f"ãƒãƒ£ãƒ³ã‚¯ {chunk_id}: {original_text[:30]}... ({len(original_text)}æ–‡å­—)")
        print(f"  â†’ å®Ÿéš›é€ä¿¡ãƒ†ã‚­ã‚¹ãƒˆ: '{text_chunk}'")
        
        tts_generator = self.tts_pipeline.run(request)
        
        audio_chunks = []
        sample_rate = None
        
        for sr, chunk in tts_generator:
            if sample_rate is None:
                sample_rate = sr
            audio_chunks.append(chunk)
        
        if audio_chunks:
            full_audio = np.concatenate(audio_chunks, axis=0)

            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãŒè¿½åŠ ã•ã‚ŒãŸå ´åˆã€å¾ŒåŠéƒ¨åˆ†ï¼ˆãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼‰ã‚’ã‚«ãƒƒãƒˆ
            if padding_added:
                # ã€ŒãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€ã®æ¨å®šæ™‚é–“: ç´„2.5ç§’
                padding_duration = 2.5
                cut_samples = int(padding_duration * sample_rate)

                # éŸ³å£°ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã‚«ãƒƒãƒˆ
                if len(full_audio) > cut_samples:
                    full_audio = full_audio[:-cut_samples]
                    print(f"  â†’ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éŸ³å£°ã‚«ãƒƒãƒˆ: {padding_duration}ç§’å‰Šé™¤")

            chunk_file = temp_dir / f"chunk_{chunk_id:03d}.wav"
            sf.write(str(chunk_file), full_audio, sample_rate)
            print(f"  â†’ {chunk_file.name}")
            return str(chunk_file)
        else:
            print(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ç”Ÿæˆå¤±æ•—")
            return None
    
    def generate_separate_speech(self, text, output_filename=None):
        """å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆâ†’ffmpegçµåˆã§éŸ³å£°ç”Ÿæˆ"""
        if self.tts_pipeline is None:
            raise RuntimeError("TTS ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
        chunk_length = self.config.get("chunk_length", 50)
        text_chunks = self.split_text(text, chunk_length)
        
        print(f"ãƒ†ã‚­ã‚¹ãƒˆã‚’ {len(text_chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")
        for i, chunk in enumerate(text_chunks, 1):
            print(f"  ãƒãƒ£ãƒ³ã‚¯{i}: {chunk}")
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = self.base_path / self.config["output_dir"]
        output_dir.mkdir(exist_ok=True)
        temp_dir = output_dir / "temp_chunks"
        temp_dir.mkdir(exist_ok=True)
        
        try:
            # å„ãƒãƒ£ãƒ³ã‚¯ã®wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
            chunk_files = []
            for i, text_chunk in enumerate(text_chunks, 1):
                # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿æ–‡æœ«å¥èª­ç‚¹ã‚’å‰Šé™¤
                if i == len(text_chunks):
                    text_chunk = text_chunk.rstrip('ã€ã€‚ï¼ï¼Ÿ.!?')

                chunk_file = self.generate_chunk_file(text_chunk, i, temp_dir)
                if chunk_file:
                    chunk_files.append(chunk_file)
            
            if not chunk_files:
                print("âŒ å…¨ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆå¤±æ•—")
                return None
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åè¨­å®š
            if output_filename is None:
                import time
                timestamp = int(time.time())
                output_filename = f"separate_{timestamp}.wav"
            
            output_path = output_dir / output_filename
            
            # ffmpegã§çµåˆ
            print(f"\\nffmpegã§ {len(chunk_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")
            concat_list = temp_dir / "concat_list.txt"
            
            # concatç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆä½œæˆï¼ˆé †åºã‚’ç¢ºå®Ÿã«ã™ã‚‹ï¼‰
            with open(concat_list, 'w', encoding='utf-8') as f:
                for chunk_file in sorted(chunk_files, key=lambda x: int(x.split('_')[-1].split('.')[0]) if '_' in str(x) else 0):
                    f.write(f"file '{os.path.basename(chunk_file)}'\n")
            
            # ffmpegå®Ÿè¡Œ
            ffmpeg_cmd = [
                'ffmpeg', '-y',  # ä¸Šæ›¸ãè¨±å¯
                '-f', 'concat',  # concatå½¢å¼
                '-safe', '0',    # ãƒ‘ã‚¹åˆ¶é™ç„¡åŠ¹
                '-i', str(concat_list),  # å…¥åŠ›ãƒªã‚¹ãƒˆ
                '-c', 'copy',    # ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã‚³ãƒ”ãƒ¼ï¼ˆå†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãªã—ï¼‰
                str(output_path)  # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
            ]
            
            result = subprocess.run(
                ffmpeg_cmd, 
                cwd=str(temp_dir),  # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«
                capture_output=True, 
                text=True
            )
            
            if result.returncode == 0:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨å†ç”Ÿæ™‚é–“ã‚’å–å¾—
                if output_path.exists():
                    file_size = output_path.stat().st_size / 1024 / 1024  # MB
                    
                    # ffprobeã§å†ç”Ÿæ™‚é–“ã‚’å–å¾—
                    probe_cmd = [
                        'ffprobe', '-v', 'quiet',
                        '-show_entries', 'format=duration',
                        '-of', 'default=noprint_wrappers=1:nokey=1',
                        str(output_path)
                    ]
                    
                    try:
                        duration_result = subprocess.run(probe_cmd, capture_output=True, text=True)
                        if duration_result.returncode == 0:
                            duration = float(duration_result.stdout.strip())
                            print(f"âœ… ffmpegçµåˆå®Œäº†: {output_filename}")
                            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f}MB")
                            print(f"   å†ç”Ÿæ™‚é–“: {duration:.2f}ç§’")
                            print(f"   ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {len(text_chunks)}")
                        else:
                            print(f"âœ… ffmpegçµåˆå®Œäº†: {output_filename} (ã‚µã‚¤ã‚º: {file_size:.2f}MB)")
                    except:
                        print(f"âœ… ffmpegçµåˆå®Œäº†: {output_filename} (ã‚µã‚¤ã‚º: {file_size:.2f}MB)")
                    
                    return str(output_path)
                else:
                    print("âŒ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                    return None
            else:
                print(f"âŒ ffmpegçµåˆã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return None
        
        finally:
            # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚’ç„¡åŠ¹åŒ–
            print("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒã—ã¾ã™")
            print(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {temp_dir}")
            if chunk_files:
                print("ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«:")
                for i, chunk_file in enumerate(chunk_files, 1):
                    print(f"  ãƒãƒ£ãƒ³ã‚¯{i}: {chunk_file}")
            # try:
            #     for chunk_file in chunk_files:
            #         if os.path.exists(chunk_file):
            #             os.remove(chunk_file)
            #     if concat_list.exists():
            #         concat_list.unlink()
            #     if temp_dir.exists() and not any(temp_dir.iterdir()):
            #         temp_dir.rmdir()
            #     print("ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            # except Exception as e:
            #     print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='GPT-SoVITS é•·æ–‡å¯¾å¿œéŸ³å£°ç”Ÿæˆ')
    parser.add_argument('text', nargs='?', help='ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ')
    parser.add_argument('output', nargs='?', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    args = parser.parse_args()
    
    try:
        print("GPT-SoVITS å€‹åˆ¥ç”Ÿæˆâ†’ffmpegçµåˆã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 50)
        
        # ffmpegã®ç¢ºèª
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
            print("âœ… ffmpegç¢ºèªOK")
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âŒ ffmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦PATHã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            return
        
        separate_tts = SeparateTTS()
        separate_tts.init_tts()
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if args.text and args.output:
            print(f"\\nã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§éŸ³å£°ç”Ÿæˆ... ({len(args.text)}æ–‡å­—)")
            result = separate_tts.generate_separate_speech(args.text, args.output)
            if result:
                print(f"ğŸ‰ éŸ³å£°ç”ŸæˆæˆåŠŸ: {args.output}")
            else:
                sys.exit(1)
        else:
            # å¾“æ¥ã®ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
            panting_text = """ã‚ã‚“ã£ã‚ã‚“ã£ã¯ã‚ã£ã¯ã‚ã£æ°—æŒã¡ã„ã„ã‚‚ã£ã¨ã‚‚ã£ã¨ã—ã¦ã‚ã‚ã‚“ã£ã ã‚æ„Ÿã˜ã¡ã‚ƒã†ã„ãã„ã£ã¡ã‚ƒã†ã¯ã‚ã¯ã‚æ¯ãŒæ¯ãŒã§ããªã„ã‚ã‚“ã‚ã‚“ã‚ã‚“ã‚„ã‚ã¦ã§ã‚‚æ­¢ã‚ãªã„ã§ã‚ã‚ã£ã‚ã‚ã£é™ç•Œã‚‚ã†é™ç•Œã‚ˆã„ãã„ãã„ã£ã¡ã‚ƒã†ãƒ¼ã¯ã‚ã£ã¯ã‚ã£ã¾ã çµ‚ã‚ã‚‰ãªã„ã‚‚ã£ã¨æ„Ÿã˜ãŸã„ã‚ã‚“ã£æ°—æŒã¡ã‚ˆã™ãã‚‹ã“ã‚“ãªã®åˆã‚ã¦ä½“ãŒéœ‡ãˆã¦æ­¢ã¾ã‚‰ãªã„ã‚ã‚“ã‚ã‚“ã‚ã‚“"""
            
            print(f"\\nå–˜ãå£°ä¸­å¿ƒãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆèª­ç‚¹ãªã—ï¼‰... ({len(panting_text)}æ–‡å­—)")
            result1 = separate_tts.generate_separate_speech(panting_text, "panting_emotional_test_no_comma.wav")
            
            if result1:
                print(f"ğŸ‰ å–˜ãå£°ä¸­å¿ƒãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()