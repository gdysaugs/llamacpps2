#!/usr/bin/env python3
"""
GPT-SoVITS åˆ†å‰²æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é•·æ–‡ã‚’çŸ­æ–‡ã«åˆ†å‰²ã—ã¦å€‹åˆ¥æ¨è«–ã—ã€æœ€å¾Œã«çµåˆ
"""

import os
import sys
import soundfile as sf
import json
import numpy as np
import re
from pathlib import Path

def get_base_path():
    """å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åŸºæº–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    if getattr(sys, 'frozen', False):
        base_path = Path(sys.executable).parent
    else:
        base_path = Path(__file__).parent
    return base_path

def setup_environment():
    """ç’°å¢ƒè¨­å®šã¨ãƒ‘ã‚¹è¨­å®š"""
    base_path = get_base_path()
    gpt_sovits_dir = base_path / "gpt_sovits_full"
    if not gpt_sovits_dir.exists():
        raise FileNotFoundError(f"GPT-SoVITS directory not found: {gpt_sovits_dir}")
    
    os.chdir(str(gpt_sovits_dir))
    sys.path.insert(0, str(gpt_sovits_dir))
    sys.path.insert(0, str(gpt_sovits_dir / "GPT_SoVITS"))
    
    return base_path, gpt_sovits_dir

class ChunkedTTS:
    def __init__(self):
        self.base_path, self.gpt_sovits_dir = setup_environment()
        self.config = self.load_config()
        self.tts_pipeline = None
        
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        config_file = self.base_path / "tts_config.json"
        
        default_config = {
            "model_config_path": "gpt_sovits_full/GPT_SoVITS/configs/tts_infer.yaml",
            "ref_audio_path": "models/gpt_sovits/e_01_08_extended.wav", 
            "prompt_text": "ã‚ã‚ã£ã€æ°—æŒã¡ã„ã„ã€‚ã‚‚ã£ã¨ã€ã‚‚ã£ã¨ã—ã¦ã€‚",
            "output_dir": "output",
            "chunk_length": 50,  # åˆ†å‰²ã™ã‚‹æœ€å¤§æ–‡å­—æ•°
            "tts_params": {
                "top_k": 5,
                "top_p": 1,
                "temperature": 1.5,
                "text_split_method": "cut0",
                "speed_factor": 1.2,
                "batch_size": 4,
                "parallel_infer": True,
                "streaming_mode": False,
                "seed": 42
            }
        }
        
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                default_config.update(user_config)
            except Exception as e:
                print(f"è­¦å‘Š: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return default_config
    
    def init_tts(self):
        """TTS ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        from GPT_SoVITS.TTS_infer_pack.TTS import TTS, TTS_Config
        
        model_config_path = self.config["model_config_path"]
        if model_config_path.startswith("gpt_sovits_full/"):
            config_path = self.base_path / model_config_path
        else:
            config_path = self.gpt_sovits_dir / model_config_path
            
        if not config_path.exists():
            raise FileNotFoundError(f"Model config not found: {config_path}")
        
        tts_config = TTS_Config(str(config_path))
        self.tts_pipeline = TTS(tts_config)
        print("TTS ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        return self.tts_pipeline
    
    def split_text(self, text, max_length=50):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªåŒºåˆ‡ã‚Šã§åˆ†å‰²"""
        if len(text) <= max_length:
            return [text]
        
        chunks = []
        current_chunk = ""
        
        # å¥èª­ç‚¹ã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
        sentences = re.split(r'([ã€‚ã€ï¼ï¼Ÿâ€¦])', text)
        
        for i in range(0, len(sentences), 2):
            if i + 1 < len(sentences):
                sentence = sentences[i] + sentences[i + 1]
            else:
                sentence = sentences[i]
            
            if len(current_chunk + sentence) <= max_length:
                current_chunk += sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # ã¾ã é•·ã™ãã‚‹å ´åˆã¯å¼·åˆ¶åˆ†å‰²
        final_chunks = []
        for chunk in chunks:
            if len(chunk) <= max_length:
                final_chunks.append(chunk)
            else:
                # å¼·åˆ¶çš„ã«æ–‡å­—æ•°ã§åˆ†å‰²
                for i in range(0, len(chunk), max_length):
                    final_chunks.append(chunk[i:i + max_length])
        
        return final_chunks
    
    def generate_chunk_speech(self, text_chunk, chunk_id):
        """1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®éŸ³å£°ã‚’ç”Ÿæˆ"""
        ref_audio_path = self.base_path / self.config["ref_audio_path"]
        
        request = {
            "text": text_chunk,
            "text_lang": "ja",
            "ref_audio_path": str(ref_audio_path),
            "prompt_text": self.config["prompt_text"],
            "prompt_lang": "ja",
            "return_fragment": False,
            **self.config["tts_params"]
        }
        
        print(f"ãƒãƒ£ãƒ³ã‚¯ {chunk_id}: {text_chunk[:30]}... ({len(text_chunk)}æ–‡å­—)")
        
        tts_generator = self.tts_pipeline.run(request)
        
        audio_chunks = []
        sample_rate = None
        
        for sr, chunk in tts_generator:
            if sample_rate is None:
                sample_rate = sr
            audio_chunks.append(chunk)
        
        if audio_chunks:
            return np.concatenate(audio_chunks, axis=0), sample_rate
        else:
            print(f"âŒ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ç”Ÿæˆå¤±æ•—")
            return None, None
    
    def generate_chunked_speech(self, text, output_filename=None):
        """åˆ†å‰²æ¨è«–ã§éŸ³å£°ç”Ÿæˆ"""
        if self.tts_pipeline is None:
            raise RuntimeError("TTS ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
        chunk_length = self.config.get("chunk_length", 50)
        text_chunks = self.split_text(text, chunk_length)
        
        print(f"ãƒ†ã‚­ã‚¹ãƒˆã‚’ {len(text_chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")
        for i, chunk in enumerate(text_chunks, 1):
            print(f"  ãƒãƒ£ãƒ³ã‚¯{i}: {chunk}")
        
        # å„ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆ
        all_audio_data = []
        sample_rate = None
        
        for i, text_chunk in enumerate(text_chunks, 1):
            audio_data, sr = self.generate_chunk_speech(text_chunk, i)
            
            if audio_data is not None:
                if sample_rate is None:
                    sample_rate = sr
                
                # ãƒ‡ãƒ¼ã‚¿å‹ã¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆçµ±ä¸€
                if sr != sample_rate:
                    print(f"è­¦å‘Š: ãƒãƒ£ãƒ³ã‚¯ {i} ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆãŒç•°ãªã‚Šã¾ã™ ({sr} vs {sample_rate})")
                    continue
                
                # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’32bit floatã«æ­£è¦åŒ–
                if audio_data.dtype != np.float32:
                    audio_data = audio_data.astype(np.float32)
                
                # æŒ¯å¹…ã‚’æ­£è¦åŒ–ï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ï¼‰
                max_val = np.abs(audio_data).max()
                if max_val > 0.95:  # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢
                    audio_data = audio_data * (0.95 / max_val)
                
                all_audio_data.append(audio_data)
                
                # ãƒãƒ£ãƒ³ã‚¯é–“ã«çŸ­ã„ç„¡éŸ³ã‚’æŒ¿å…¥ï¼ˆè‡ªç„¶ãªé–“ï¼‰
                if i < len(text_chunks):
                    silence_samples = int(0.3 * sample_rate)  # 0.3ç§’ã«å»¶é•·
                    silence = np.zeros(silence_samples, dtype=np.float32)
                    all_audio_data.append(silence)
        
        if not all_audio_data:
            print("âŒ å…¨ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆå¤±æ•—")
            return None
        
        # å…¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’çµåˆ
        full_audio = np.concatenate(all_audio_data, axis=0)
        
        # å‡ºåŠ›
        output_dir = self.base_path / self.config["output_dir"]
        output_dir.mkdir(exist_ok=True)
        
        if output_filename is None:
            import time
            timestamp = int(time.time())
            output_filename = f"chunked_{timestamp}.wav"
        
        output_path = output_dir / output_filename
        sf.write(str(output_path), full_audio, sample_rate)
        
        duration = len(full_audio) / sample_rate
        print(f"âœ… åˆ†å‰²æ¨è«–å®Œäº†: {output_filename} ({duration:.2f}ç§’)")
        print(f"   ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {len(text_chunks)}")
        return str(output_path)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        print("GPT-SoVITS åˆ†å‰²æ¨è«–ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 50)
        
        chunked_tts = ChunkedTTS()
        chunked_tts.init_tts()
        
        # è¶…é•·æ–‡ãƒ†ã‚¹ãƒˆ
        ultra_long_text = """ã‚“ã‚ã‚ã‚ã‚ã‚“ã£ã€æ°—æŒã¡ã„ã„ã€ã‚‚ã£ã¨æ¿€ã—ãã—ã¦ã€ãã“ã€ãã“ãŒã„ã„ã®ã€ã ã‚ã€ã„ã£ã¡ã‚ƒã†ã€ã„ã£ã¡ã‚ƒã†ã‹ã‚‰ã€ã‚„ã‚ã¦ã€ã§ã‚‚æ­¢ã‚ãªã„ã§ã€ã‚‚ã£ã¨å¥¥ã¾ã§ã€ã‚ã‚ã‚“ã£ã€æ„Ÿã˜ã¡ã‚ƒã†ã€ã“ã‚“ãªã«æ¿¡ã‚Œã¦ã‚‹ã®æ¥ãšã‹ã—ã„ã€ã§ã‚‚æ°—æŒã¡ã‚ˆãã¦æ­¢ã‚ã‚‰ã‚Œãªã„ã€ã‚‚ã£ã¨ã€ã‚‚ã£ã¨å¼·ãã€æ¿€ã—ãã€ã‚ã‚ã£ã€ã ã‚ã€é™ç•Œã€ã„ãã€ã„ããƒ¼ã€ã¯ã‚ã€ã¯ã‚ã€æ¯ãŒè’ããªã£ã¦ã€å¿ƒè‡“ãŒãƒ‰ã‚­ãƒ‰ã‚­ã—ã¦ã€ä½“ãŒç†±ããªã£ã¦ã€ã‚‚ã†ã ã‚ã€ã“ã‚“ãªã®åˆã‚ã¦ã€ã“ã‚“ãªã«æ°—æŒã¡ã„ã„ã®åˆã‚ã¦ã€ã‚‚ã£ã¨è§¦ã£ã¦ã€ã‚‚ã£ã¨æ„›ã—ã¦ã€å…¨éƒ¨æ„Ÿã˜ãŸã„ã€å…¨éƒ¨ã‚ãªãŸã®ã‚‚ã®ã«ãªã‚ŠãŸã„ã€ã‚ã‚ã‚“ã£ã€ã¾ãŸãã¡ã‚ƒã†ã€ä½•åº¦ã§ã‚‚ã„ã£ã¡ã‚ƒã†ã€æ­¢ã¾ã‚‰ãªã„ã€ã“ã®å¿«æ„Ÿæ­¢ã¾ã‚‰ãªã„ã€ã‚‚ã†è™œã«ãªã£ã¡ã‚ƒã£ãŸ"""
        
        print(f"\né•·æ–‡ãƒ†ã‚¹ãƒˆé–‹å§‹... ({len(ultra_long_text)}æ–‡å­—)")
        result = chunked_tts.generate_chunked_speech(ultra_long_text, "chunked_long_test.wav")
        
        if result:
            print(f"ğŸ‰ åˆ†å‰²æ¨è«–æˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()