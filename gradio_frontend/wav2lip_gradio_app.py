#!/usr/bin/env python3
"""
Wav2Lip Gradio Frontend Application
é«˜å“è³ªãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆã®ãŸã‚ã®Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import gradio as gr
import os
import sys
import subprocess
import tempfile
import uuid
import time
from pathlib import Path
from datetime import datetime
from typing import Optional, Tuple, Dict, Any

# Wav2Lipãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
WAV2LIP_ROOT = Path(__file__).parent.parent
sys.path.append(str(WAV2LIP_ROOT))

class Wav2LipGradioApp:
    def __init__(self):
        """Gradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–"""
        self.wav2lip_root = WAV2LIP_ROOT
        self.wav2lip_script = self.wav2lip_root / "wav2lip_subprocess.py"
        self.temp_dir = Path(tempfile.gettempdir()) / "wav2lip_gradio"
        self.temp_dir.mkdir(exist_ok=True)

        # ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
        self.supported_video_formats = [".mp4", ".avi", ".mov", ".mkv", ".webm"]
        self.supported_audio_formats = [".mp3", ".wav", ".m4a", ".aac", ".flac"]

    def validate_files(self, video_file: Optional[str], audio_file: Optional[str]) -> Tuple[bool, str]:
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
        if not video_file:
            return False, "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        if not audio_file:
            return False, "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®æ¤œè¨¼
        video_ext = Path(video_file).suffix.lower()
        audio_ext = Path(audio_file).suffix.lower()

        if video_ext not in self.supported_video_formats:
            return False, f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å‹•ç”»å½¢å¼ã§ã™: {video_ext}"

        if audio_ext not in self.supported_audio_formats:
            return False, f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„éŸ³å£°å½¢å¼ã§ã™: {audio_ext}"

        return True, "ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼OK"

    def generate_output_filename(self) -> str:
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        return f"wav2lip_result_{timestamp}_{unique_id}.mp4"

    def run_wav2lip_subprocess(
        self,
        video_file: str,
        audio_file: str,
        use_gfpgan: bool = True,
        device: str = "cuda"
    ) -> Tuple[Optional[str], str, Dict[str, Any]]:
        """
        Wav2Lipã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œ (onnxruntime-gpu 1.15.1æœ€é©åŒ–ç‰ˆ)

        Returns:
            Tuple[Optional[str], str, Dict[str, Any]]: (å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, çµ±è¨ˆæƒ…å ±)
        """
        try:
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
            output_filename = self.generate_output_filename()
            output_path = self.temp_dir / output_filename

            # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®æ§‹ç¯‰ï¼ˆæ–°ã—ã„ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆå¯¾å¿œï¼‰
            cmd = [
                sys.executable,
                str(self.wav2lip_script),
                video_file,
                audio_file,
                "-o", str(output_path),
                "--device", device
            ]

            # GFPGAN ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
            if not use_gfpgan:
                cmd.append("--no-gfpgan")

            # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ
            start_time = time.time()

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                cwd=str(self.wav2lip_root)
            )

            end_time = time.time()
            execution_time = end_time - start_time

            # çµ±è¨ˆæƒ…å ±ã®ç”Ÿæˆï¼ˆæ–°ã—ã„ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆå¯¾å¿œï¼‰
            stats = {
                "success": True,
                "execution_time": execution_time,
                "output_file": str(output_path),
                "settings": {
                    "use_gfpgan": use_gfpgan,
                    "device": device
                }
            }

            # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
            gfpgan_status = 'æœ‰åŠ¹ (GPUåŠ é€Ÿ)' if use_gfpgan else 'ç„¡åŠ¹ (é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰)'

            log_message = f"""âœ… å‡¦ç†å®Œäº†ï¼ (onnxruntime-gpu 1.15.1æœ€é©åŒ–ç‰ˆ)
â±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’
ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_filename}
ğŸ“Š è¨­å®š:
  - GFPGANé¡”è£œæ­£: {gfpgan_status}
  - å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹: {device.upper()}
  - RetinaFaceæ¤œå‡º: GPUåŠ é€Ÿ
  - å…ƒè§£åƒåº¦ä¿æŒ: æœ‰åŠ¹

ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
{result.stdout.split('Face detection:')[1].split('Inference:')[0] if 'Face detection:' in result.stdout else ''}
{result.stdout.split('Inference:')[1].split('ffmpeg')[0] if 'Inference:' in result.stdout else ''}

ğŸ“ è©³ç´°ãƒ­ã‚°:
{result.stdout}
"""

            if output_path.exists():
                # Return absolute path for Gradio
                abs_output_path = output_path.resolve()
                return str(abs_output_path), log_message, stats
            else:
                return None, f"âŒ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\n{log_message}", stats

        except subprocess.CalledProcessError as e:
            error_message = f"""âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ
ğŸ’¥ ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {e.returncode}

ğŸ“ stdout:
{e.stdout}

ğŸ“ stderr:
{e.stderr}
"""
            stats = {"success": False, "error": str(e)}
            return None, error_message, stats

        except Exception as e:
            error_message = f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            stats = {"success": False, "error": str(e)}
            return None, error_message, stats

    def process_video(
        self,
        video_file,
        audio_file,
        use_gfpgan,
        device,
        progress=gr.Progress()
    ):
        """
        ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°ï¼ˆGradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç”¨ - onnxruntime-gpu 1.15.1å¯¾å¿œï¼‰
        """
        try:
            progress(0.1, desc="ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­...")

            # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            is_valid, validation_message = self.validate_files(video_file, audio_file)
            if not is_valid:
                return None, f"âŒ {validation_message}", None

            progress(0.2, desc="RetinaFace GPUæ¤œå‡ºãƒ»Wav2Lipæ¨è«–é–‹å§‹...")

            # Wav2Lipå®Ÿè¡Œï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            output_file, log_message, stats = self.run_wav2lip_subprocess(
                video_file,
                audio_file,
                use_gfpgan,
                device
            )

            progress(1.0, desc="å‡¦ç†å®Œäº†ï¼GPUåŠ é€Ÿã§é«˜é€Ÿå‡¦ç†ã•ã‚Œã¾ã—ãŸ")

            return output_file, log_message, stats

        except Exception as e:
            error_msg = f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            return None, error_msg, None

    def create_interface(self):
        """Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½œæˆ"""

        # ã‚«ã‚¹ã‚¿ãƒ CSS
        custom_css = """
        .gradio-container {
            max-width: 1200px !important;
        }
        .output-video {
            max-height: 500px;
        }
        .log-output {
            max-height: 400px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
        """

        with gr.Blocks(
            title="Wav2Lip ONNX High Quality - Web Interface",
            css=custom_css,
            theme=gr.themes.Soft()
        ) as interface:

            # ãƒ˜ãƒƒãƒ€ãƒ¼
            gr.Markdown("""
            # ğŸ¬ Wav2Lip ONNX GPU - Web Interface (v2.0)

            onnxruntime-gpu 1.15.1æœ€é©åŒ–ç‰ˆã€‚RetinaFace GPUæ¤œå‡º + GFPGAN GPUåŠ é€Ÿã«ã‚ˆã‚‹é«˜å“è³ªãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã€‚

            ## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
            - **Face detection**: ~76 it/s (RetinaFace GPU)
            - **Inference**: ~6.3 it/s (Wav2Lip GPU)
            - **å‡¦ç†æ™‚é–“**: ç´„31ç§’ (5ç§’å‹•ç”»ã€GFPGANæœ‰åŠ¹)

            ## ğŸ“‹ ä½¿ç”¨æ–¹æ³•
            1. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            2. GFPGANè¨­å®šã¨ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
            3. ã€ŒğŸš€ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”Ÿæˆé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            4. GPUåŠ é€Ÿã§é«˜é€Ÿå‡¦ç†ã€å®Œäº†å¾Œãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            """)

            with gr.Row():
                # å·¦å´: å…¥åŠ›ã¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                with gr.Column(scale=1):
                    gr.Markdown("## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

                    video_input = gr.File(
                        label="ğŸ“¹ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«",
                        file_types=[".mp4", ".avi", ".mov", ".mkv", ".webm"],
                        type="filepath"
                    )

                    audio_input = gr.File(
                        label="ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«",
                        file_types=[".mp3", ".wav", ".m4a", ".aac", ".flac"],
                        type="filepath"
                    )

                    gr.Markdown("## âš™ï¸ å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³")

                    with gr.Group():
                        use_gfpgan = gr.Checkbox(
                            label="âœ¨ GFPGANé¡”è£œæ­£ã‚’ä½¿ç”¨",
                            value=True,
                            info="é¡”ç”»è³ªå‘ä¸Šï¼ˆå‡¦ç†æ™‚é–“ãŒé•·ããªã‚Šã¾ã™ï¼‰"
                        )


                        device = gr.Radio(
                            label="ğŸ’» å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹",
                            choices=["cuda", "cpu"],
                            value="cuda",
                            info="CUDAãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯cudaæ¨å¥¨"
                        )

                    # å‡¦ç†é–‹å§‹ãƒœã‚¿ãƒ³
                    process_btn = gr.Button(
                        "ğŸš€ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”Ÿæˆé–‹å§‹",
                        variant="primary",
                        size="lg"
                    )

                # å³å´: å‡ºåŠ›ã¨çµæœ
                with gr.Column(scale=1):
                    gr.Markdown("## ğŸ“º å‡¦ç†çµæœ")

                    output_video = gr.Video(
                        label="ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»",
                        elem_classes=["output-video"]
                    )

                    download_btn = gr.DownloadButton(
                        label="ğŸ’¾ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        variant="secondary",
                        visible=False
                    )

                    gr.Markdown("## ğŸ“Š å‡¦ç†ãƒ­ã‚°")

                    log_output = gr.Textbox(
                        label="ãƒ­ã‚°ãƒ»çµ±è¨ˆæƒ…å ±",
                        lines=15,
                        max_lines=20,
                        elem_classes=["log-output"],
                        interactive=False
                    )

            # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            def on_process_click(*args):
                result = self.process_video(*args)
                output_file, log_message, stats = result

                if output_file and Path(output_file).exists():
                    return (
                        output_file,  # output_video
                        log_message,  # log_output
                        gr.update(visible=True, value=output_file)  # download_btn
                    )
                else:
                    return (
                        None,  # output_video
                        log_message,  # log_output
                        gr.update(visible=False)  # download_btn
                    )

            process_btn.click(
                fn=on_process_click,
                inputs=[
                    video_input,
                    audio_input,
                    use_gfpgan,
                    device
                ],
                outputs=[
                    output_video,
                    log_output,
                    download_btn
                ]
            )

            # ãƒ•ãƒƒã‚¿ãƒ¼
            gr.Markdown("""
            ---

            **ğŸ”§ é–‹ç™ºæƒ…å ±**
            - **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v1.3 - ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å¯¾å¿œç‰ˆ
            - **é–‹ç™ºè€…**: Claude Code Assistant
            - **æ›´æ–°æ—¥**: 2025-09-13

            **ğŸ“ æ³¨æ„äº‹é …**
            - å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚„é•·æ™‚é–“ã®å‹•ç”»ã¯å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™
            - GFPGANä½¿ç”¨æ™‚ã¯å‡¦ç†æ™‚é–“ãŒå¤§å¹…ã«å¢—åŠ ã—ã¾ã™
            - CUDAå¯¾å¿œGPUãŒæ¨å¥¨ã•ã‚Œã¾ã™
            """)

        return interface

    def launch(self, **kwargs):
        """Gradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•"""
        interface = self.create_interface()

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        launch_kwargs = {
            "server_name": "0.0.0.0",
            "server_port": 7860,
            "share": False,
            "debug": True,
            "inbrowser": True
        }
        launch_kwargs.update(kwargs)

        print("ğŸš€ Wav2Lip Gradio Frontend Starting...")
        print(f"ğŸ“ Wav2Lip Root: {self.wav2lip_root}")
        print(f"ğŸ“ Temp Directory: {self.temp_dir}")
        print(f"ğŸŒ Server: http://localhost:{launch_kwargs['server_port']}")

        # Add allowed_paths for output directory (Gradio 5.x compatibility)
        launch_kwargs["allowed_paths"] = [str(self.wav2lip_root / "output")]

        interface.launch(**launch_kwargs)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    app = Wav2LipGradioApp()
    app.launch()

if __name__ == "__main__":
    main()