#!/usr/bin/env python3
"""
FaceFusionçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆæˆåŠŸã—ãŸCLIã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆãƒ™ãƒ¼ã‚¹ï¼‰
Gradio Frontendç”¨ã®FaceFusion é †æ¬¡å‡¦ç†ï¼ˆFace Swap â†’ GFPGANï¼‰çµ±åˆæ©Ÿèƒ½
"""

import subprocess
import sys
import os
import time
import gc
import psutil
import shutil
import fcntl
from pathlib import Path
from typing import Optional, Tuple, Dict, Any


class FaceFusionIntegration:
    """FaceFusionçµ±åˆå‡¦ç†ã‚¯ãƒ©ã‚¹ï¼ˆFace Swap + GFPGANé †æ¬¡å‡¦ç†ï¼‰"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.wav2lip_root = Path(__file__).parent.parent

        # FaceFusionç’°å¢ƒãƒ‘ã‚¹ (Dockerå¯¾å¿œ)
        if os.path.exists("/app/facefusion_env"):
            # Dockerç’°å¢ƒ
            self.facefusion_env = Path("/app/facefusion_env")
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
            self.facefusion_env = self.wav2lip_root / "facefusion_env"
        self.facefusion_script = self.wav2lip_root / "facefusion/facefusion.py"
        self.temp_dir = Path("/tmp/gradio_facefusion")
        self.temp_dir.mkdir(exist_ok=True)

        # ã‚µãƒãƒ¼ãƒˆã™ã‚‹ç”»åƒãƒ»å‹•ç”»å½¢å¼
        self.supported_image_formats = [".jpg", ".jpeg", ".png", ".bmp", ".webp"]
        self.supported_video_formats = [".mp4", ".avi", ".mov", ".mkv", ".webm"]

    def setup_cuda_environment(self) -> str:
        """CUDAç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š"""
        venv_lib = self.facefusion_env / "lib/python3.10/site-packages"
        cuda_paths = [
            venv_lib / "nvidia/cuda_runtime/lib",
            venv_lib / "nvidia/cudnn/lib",
            venv_lib / "nvidia/cublas/lib",
            venv_lib / "nvidia/cufft/lib"
        ]

        ld_library_path = ":".join(str(p) for p in cuda_paths)
        current_path = os.environ.get("LD_LIBRARY_PATH", "")
        if current_path:
            ld_library_path = f"{ld_library_path}:{current_path}"

        return ld_library_path

    def get_memory_info(self) -> Tuple[float, float]:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        gpu_memory = self.get_gpu_memory()
        return memory_mb, gpu_memory

    def get_gpu_memory(self) -> float:
        """GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
        try:
            import torch
            if torch.cuda.is_available():
                return torch.cuda.memory_allocated() / 1024 / 1024
        except:
            pass
        return 0

    def clear_memory(self):
        """ãƒ¡ãƒ¢ãƒªã‚’æ˜ç¤ºçš„ã«è§£æ”¾"""
        # Python ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()

        # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
        except ImportError:
            pass
        except Exception:
            pass

        # å†åº¦ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()

    def monitor_process(self, process, step_name, timeout=600) -> Tuple[bool, float, float]:
        """ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        start_time = time.time()
        max_memory = 0
        output_lines = []
        last_output_time = start_time

        while process.poll() is None:
            try:
                # ãƒ—ãƒ­ã‚»ã‚¹ã®å‡ºåŠ›ã‚’èª­ã¿å–ã‚‹ï¼ˆãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                if process.stdout:
                    try:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿ã‚’ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã«è¨­å®š
                        fd = process.stdout.fileno()
                        fl = fcntl.fcntl(fd, fcntl.F_GETFL)
                        fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
                    except (OSError, AttributeError):
                        # ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°è¨­å®šã«å¤±æ•—ã—ãŸå ´åˆã¯ãã®ã¾ã¾ç¶šè¡Œ
                        pass

                    try:
                        line = process.stdout.readline()
                        if line and line.strip():
                            output_lines.append(line.strip())
                            print(f"[{step_name}] {line.strip()}")
                            last_output_time = time.time()
                    except (BlockingIOError, OSError):
                        # ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°èª­ã¿å–ã‚Šã§ä½•ã‚‚ãªã„å ´åˆ
                        pass

                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
                try:
                    proc_info = psutil.Process(process.pid)
                    memory_mb = proc_info.memory_info().rss / 1024 / 1024
                    max_memory = max(max_memory, memory_mb)
                except psutil.NoSuchProcess:
                    break

                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    print(f"[{step_name}] â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ({timeout}ç§’) - ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†")
                    process.terminate()
                    try:
                        process.wait(timeout=10)
                    except subprocess.TimeoutExpired:
                        process.kill()
                        process.wait()
                    return False, max_memory, elapsed

                # å‡ºåŠ›ãŒãªã„å ´åˆã®ç„¡å¿œç­”ãƒã‚§ãƒƒã‚¯ï¼ˆ300ç§’ï¼‰
                if time.time() - last_output_time > 300:
                    print(f"[{step_name}] âš ï¸ 300ç§’é–“å‡ºåŠ›ãªã— - å‡¦ç†ç¶™ç¶šä¸­...")
                    last_output_time = time.time()  # ãƒªã‚»ãƒƒãƒˆã—ã¦ç¶™ç¶š

            except Exception as e:
                print(f"[{step_name}] ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                break

            time.sleep(0.5)  # CPUä½¿ç”¨ç‡ã‚’ä¸‹ã’ã‚‹ãŸã‚å°‘ã—é•·ã‚ã«

        # æ®‹ã‚Šã®å‡ºåŠ›ã‚’èª­ã¿å–ã‚‹
        if process.stdout:
            remaining_output = process.stdout.read()
            if remaining_output:
                for line in remaining_output.strip().split('\n'):
                    if line.strip():
                        output_lines.append(line.strip())
                        print(f"[{step_name}] {line.strip()}")

        elapsed = time.time() - start_time
        success = process.returncode == 0

        print(f"[{step_name}] å®Œäº† - return code: {process.returncode}, æ™‚é–“: {elapsed:.2f}ç§’")

        return success, max_memory, elapsed

    def validate_inputs(self, source_image: str, target_video: str) -> Tuple[bool, str]:
        """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼"""
        try:
            # ã‚½ãƒ¼ã‚¹ç”»åƒæ¤œè¨¼
            if not source_image or not Path(source_image).exists():
                return False, "âŒ ã‚½ãƒ¼ã‚¹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

            image_ext = Path(source_image).suffix.lower()
            if image_ext not in self.supported_image_formats:
                return False, f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ç”»åƒå½¢å¼: {image_ext}"

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‹•ç”»æ¤œè¨¼
            if not target_video or not Path(target_video).exists():
                return False, "âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

            video_ext = Path(target_video).suffix.lower()
            if video_ext not in self.supported_video_formats:
                return False, f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å‹•ç”»å½¢å¼: {video_ext}"

            # FaceFusionç’°å¢ƒç¢ºèª
            if not self.is_available():
                return False, "âŒ FaceFusionç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

            return True, "âœ… FaceFusionå…¥åŠ›æ¤œè¨¼OK"

        except Exception as e:
            return False, f"âŒ å…¥åŠ›æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"

    def prepare_input_files(self, source_image: str, target_video: str) -> Tuple[Path, Path]:
        """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™"""
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
        timestamp = int(time.time())

        # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèªãƒ»ä½œæˆ
        input_dir = self.wav2lip_root / "input"
        input_dir.mkdir(exist_ok=True)

        # ã‚½ãƒ¼ã‚¹ç”»åƒã®ã‚³ãƒ”ãƒ¼ï¼ˆæ—¢å­˜ã®å ´åˆã¯ä¸Šæ›¸ãï¼‰
        source_ext = Path(source_image).suffix
        source_dest = input_dir / f"facefusion_source_{timestamp}{source_ext}"
        shutil.copy2(source_image, source_dest)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‹•ç”»ã®ã‚³ãƒ”ãƒ¼
        video_ext = Path(target_video).suffix
        video_dest = input_dir / f"facefusion_target_{timestamp}{video_ext}"
        shutil.copy2(target_video, video_dest)

        return source_dest, video_dest

    def process_face_swap_with_gfpgan(
        self,
        source_image: str,
        target_video: str,
        progress_callback=None
    ) -> Dict[str, Any]:
        """
        FaceFusioné¡”äº¤æ›å‡¦ç†ï¼ˆFace Swap â†’ GFPGANé †æ¬¡å‡¦ç†ï¼‰

        Args:
            source_image: ã‚½ãƒ¼ã‚¹ç”»åƒãƒ‘ã‚¹
            target_video: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‹•ç”»ãƒ‘ã‚¹
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

        Returns:
            å‡¦ç†çµæœè¾æ›¸
        """
        start_time = time.time()

        try:
            # é€²æ—æ›´æ–°
            if progress_callback:
                progress_callback(0.0, "ğŸ” FaceFusionå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­...")

            # å…¥åŠ›æ¤œè¨¼
            is_valid, message = self.validate_inputs(source_image, target_video)
            if not is_valid:
                return {
                    "success": False,
                    "message": message,
                    "video_path": None,
                    "stats": {}
                }

            # é€²æ—æ›´æ–°
            if progress_callback:
                progress_callback(0.1, "ğŸ“ FaceFusionãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™ä¸­...")

            # ãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™
            source_dest, video_dest = self.prepare_input_files(source_image, target_video)

            # å‡ºåŠ›ãƒ‘ã‚¹è¨­å®š
            timestamp = int(time.time())
            temp_video = self.wav2lip_root / "output/facefusion" / f"temp_{timestamp}.mp4"
            output_video = self.wav2lip_root / "output/facefusion" / f"gradio_facefusion_{timestamp}.mp4"
            output_video.parent.mkdir(parents=True, exist_ok=True)

            # CUDAç’°å¢ƒè¨­å®š
            env = os.environ.copy()
            env["LD_LIBRARY_PATH"] = self.setup_cuda_environment()

            # åˆæœŸãƒ¡ãƒ¢ãƒªçŠ¶æ³
            initial_mem = self.get_memory_info()

            # Step 1: Face Swapper
            if progress_callback:
                progress_callback(0.2, "ğŸ­ Step 1: é¡”äº¤æ›å‡¦ç†ä¸­...")

            # æˆåŠŸã—ãŸå˜ä½“ãƒ†ã‚¹ãƒˆé€šã‚Šã®ã‚³ãƒãƒ³ãƒ‰æ§‹æˆ
            cmd1 = [
                "bash", "-c",
                f"cd {self.wav2lip_root / 'facefusion'} && " +
                f"source {self.facefusion_env / 'bin/activate'} && " +
                f"export LD_LIBRARY_PATH='{env['LD_LIBRARY_PATH']}' && " +
                f"export PYTHONPATH='/app/facefusion:$PYTHONPATH' && " +
                f"{self.facefusion_env}/bin/python facefusion.py headless-run " +
                f"--source-paths {source_dest} " +
                f"--target-path {video_dest} " +
                f"--output-path {temp_video} " +
                f"--temp-path /app/models/facefusion " +
                f"--execution-providers cuda " +
                f"--face-detector-model retinaface " +
                f"--face-detector-size 320x320 " +
                f"--face-detector-score 0.3 " +
                f"--face-swapper-model inswapper_128 " +
                f"--processors face_swapper " +
                f"--execution-thread-count 2 " +
                f"--video-memory-strategy tolerant " +
                f"--log-level info"
            ]

            print(f"[Face Swap] ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œä¸­: {' '.join(cmd1[:2])}...")
            process1 = subprocess.Popen(cmd1)

            # bash -cã‚³ãƒãƒ³ãƒ‰ã¯ç›´æ¥å¾…æ©Ÿï¼ˆmonitor_processã¯ä½¿ã‚ãªã„ï¼‰
            start_time = time.time()
            return_code = process1.wait()
            elapsed_time1 = time.time() - start_time
            success1 = return_code == 0
            max_memory1 = 0

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
            print(f"ğŸ” DEBUG Face Swap: success1={success1}, return_code={process1.returncode}, temp_video.exists()={temp_video.exists()}")

            if not success1:
                return {
                    "success": False,
                    "message": f"âŒ FaceFusion Face Swapå¤±æ•— (return_code: {process1.returncode})",
                    "video_path": None,
                    "stats": {"face_swap_time": elapsed_time1}
                }

            # Step 2: GFPGAN Enhancement
            if progress_callback:
                progress_callback(0.6, "âœ¨ Step 2: GFPGANå“è³ªå‘ä¸Šä¸­...")

            # æˆåŠŸã—ãŸå˜ä½“ãƒ†ã‚¹ãƒˆé€šã‚Šã®ã‚³ãƒãƒ³ãƒ‰æ§‹æˆ
            cmd2 = [
                "bash", "-c",
                f"cd {self.wav2lip_root / 'facefusion'} && " +
                f"source {self.facefusion_env / 'bin/activate'} && " +
                f"export LD_LIBRARY_PATH='{env['LD_LIBRARY_PATH']}' && " +
                f"export PYTHONPATH='/app/facefusion:$PYTHONPATH' && " +
                f"{self.facefusion_env}/bin/python facefusion.py headless-run " +
                f"--source-paths {temp_video} " +
                f"--target-path {temp_video} " +
                f"--output-path {output_video} " +
                f"--temp-path /app/models/facefusion " +
                f"--execution-providers cuda " +
                f"--processors face_enhancer " +
                f"--face-enhancer-model gfpgan_1.4 " +
                f"--face-enhancer-blend 25 " +
                f"--face-enhancer-weight 0.5 " +
                f"--execution-thread-count 2 " +
                f"--video-memory-strategy tolerant " +
                f"--log-level info"
            ]

            print(f"[GFPGAN Enhancement] ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œä¸­: {' '.join(cmd2[:2])}...")
            process2 = subprocess.Popen(cmd2)

            # bash -cã‚³ãƒãƒ³ãƒ‰ã¯ç›´æ¥å¾…æ©Ÿï¼ˆmonitor_processã¯ä½¿ã‚ãªã„ï¼‰
            start_time2 = time.time()
            return_code2 = process2.wait()
            elapsed_time2 = time.time() - start_time2
            success2 = return_code2 == 0
            max_memory2 = 0

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
            print(f"ğŸ” DEBUG GFPGAN: success2={success2}, return_code={process2.returncode}, output_video.exists()={output_video.exists()}")

            if not success2:
                return {
                    "success": False,
                    "message": f"âŒ FaceFusion GFPGAN Enhancementå¤±æ•— (return_code: {process2.returncode})",
                    "video_path": None,
                    "stats": {
                        "face_swap_time": elapsed_time1,
                        "gfpgan_time": elapsed_time2
                    }
                }

            # Step 3: éŸ³å£°å¾©å…ƒå‡¦ç†
            if progress_callback:
                progress_callback(0.85, "ğŸµ éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯å¾©å…ƒä¸­...")

            final_output = self.wav2lip_root / "output/facefusion" / f"gradio_facefusion_with_audio_{timestamp}.mp4"
            success3 = self.restore_audio_track(str(video_dest), str(output_video), str(final_output))

            if success3:
                output_video = final_output

            # å‡¦ç†å®Œäº†å¾Œã®ãƒ¡ãƒ¢ãƒªè§£æ”¾
            if progress_callback:
                progress_callback(0.9, "ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")

            self.clear_memory()

            # ãƒ¡ãƒ¢ãƒªè§£æ”¾å¾Œã®çŠ¶æ³ç¢ºèª
            final_mem = self.get_memory_info()

            # å…¨ä½“ã®çµæœ
            total_elapsed = time.time() - start_time
            max_memory = max(max_memory1, max_memory2)

            if progress_callback:
                progress_callback(1.0, "âœ… FaceFusionå‡¦ç†å®Œäº†!")

            # çµ±è¨ˆæƒ…å ±
            stats = {
                "face_swap_time": elapsed_time1,
                "gfpgan_time": elapsed_time2,
                "audio_restore": success3 if 'success3' in locals() else False,
                "total_time": total_elapsed,
                "max_memory_mb": max_memory,
                "initial_memory": initial_mem,
                "final_memory": final_mem
            }

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.cleanup_temp_files([source_dest, video_dest, temp_video])

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
            print(f"ğŸ” DEBUG Final: output_video={output_video}")
            print(f"ğŸ” DEBUG Final: output_video.exists()={output_video.exists()}")
            if success3 and 'final_output' in locals():
                print(f"ğŸ” DEBUG Final: final_output={final_output}")
                print(f"ğŸ” DEBUG Final: final_output.exists()={final_output.exists() if final_output else 'N/A'}")

            if output_video.exists():
                size_mb = output_video.stat().st_size / (1024 * 1024)
                stats["output_size_mb"] = size_mb

                audio_msg = " + éŸ³å£°å¾©å…ƒ" if success3 else ""
                message = f"âœ… FaceFusionå®Œäº†: Face Swap {elapsed_time1:.2f}ç§’ + GFPGAN {elapsed_time2:.2f}ç§’{audio_msg} = åˆè¨ˆ {total_elapsed:.2f}ç§’"

                print(f"ğŸ” DEBUG Final: returning SUCCESS with video_path={str(output_video)}")
                return {
                    "success": True,
                    "message": message,
                    "video_path": str(output_video),
                    "stats": stats
                }
            else:
                print(f"ğŸ” DEBUG Final: returning FAILURE - output file does not exist")
                return {
                    "success": False,
                    "message": "âŒ FaceFusionå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ",
                    "video_path": None,
                    "stats": stats
                }

        except Exception as e:
            total_elapsed = time.time() - start_time
            return {
                "success": False,
                "message": f"âŒ FaceFusionå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                "video_path": None,
                "stats": {"total_time": total_elapsed}
            }

    def restore_audio_track(self, original_video: str, processed_video: str, output_video: str) -> bool:
        """
        FaceFusionå‡¦ç†å¾Œã®ãƒ“ãƒ‡ã‚ªã«å…ƒã®éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’å¾©å…ƒ

        Args:
            original_video: å…ƒã®å‹•ç”»ï¼ˆéŸ³å£°ä»˜ãï¼‰
            processed_video: FaceFusionå‡¦ç†æ¸ˆã¿å‹•ç”»ï¼ˆéŸ³å£°ãªã—ï¼‰
            output_video: å‡ºåŠ›å‹•ç”»ãƒ‘ã‚¹ï¼ˆéŸ³å£°ä»˜ãï¼‰

        Returns:
            æˆåŠŸ: True, å¤±æ•—: False
        """
        try:
            import subprocess

            # ffmpegã§éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’å¾©å…ƒ
            cmd = [
                "ffmpeg",
                "-i", processed_video,  # ãƒ“ãƒ‡ã‚ªã‚½ãƒ¼ã‚¹ï¼ˆFaceFusionå‡¦ç†æ¸ˆã¿ï¼‰
                "-i", original_video,   # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚½ãƒ¼ã‚¹ï¼ˆå…ƒå‹•ç”»ï¼‰
                "-c:v", "copy",         # ãƒ“ãƒ‡ã‚ªã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã‚’ã‚³ãƒ”ãƒ¼
                "-c:a", "aac",          # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’AACã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                "-map", "0:v:0",        # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ“ãƒ‡ã‚ªãƒˆãƒ©ãƒƒã‚¯
                "-map", "1:a:0",        # äºŒç•ªç›®ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯
                "-shortest",            # çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹
                "-y",                   # ä¸Šæ›¸ãç¢ºèªãªã—
                output_video
            ]

            process = subprocess.Popen(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )

            process.wait()

            return process.returncode == 0 and Path(output_video).exists()

        except Exception as e:
            print(f"éŸ³å£°å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def cleanup_temp_files(self, file_paths):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        for file_path in file_paths:
            try:
                if Path(file_path).exists():
                    Path(file_path).unlink()
            except Exception:
                pass  # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã«å¤±æ•—ã‚’ç„¡è¦–

    def is_available(self) -> bool:
        """FaceFusionæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return (
            self.facefusion_script.exists() and
            self.facefusion_env.exists() and
            (self.facefusion_env / "bin/python").exists()
        )