#!/usr/bin/env python3
"""
SoVITS-FaceFusion-Wav2Lip çµ±åˆGradioãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ + é¡”äº¤æ› + ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®3æ®µéšçµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import gradio as gr
import sys
import tempfile
import time
import gc
from pathlib import Path
from typing import Optional, Tuple, Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
WAV2LIP_ROOT = Path(__file__).parent.parent
sys.path.append(str(WAV2LIP_ROOT))

# çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from gradio_frontend.sovits_wav2lip_integration import SOVITSWav2LipIntegration
    from gradio_frontend.facefusion_integration import FaceFusionIntegration
    INTEGRATION_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Could not import integration modules: {e}")
    INTEGRATION_AVAILABLE = False

class ThreeStageIntegratedApp:
    """3æ®µéšçµ±åˆGradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.sovits_wav2lip = SOVITSWav2LipIntegration() if INTEGRATION_AVAILABLE else None
        self.facefusion = FaceFusionIntegration() if INTEGRATION_AVAILABLE else None
        self.temp_dir = Path("/tmp/gradio_three_stage")
        self.temp_dir.mkdir(exist_ok=True)

        # ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
        self.supported_video_formats = [".mp4", ".avi", ".mov", ".mkv", ".webm"]
        self.supported_audio_formats = [".mp3", ".wav", ".m4a", ".aac", ".flac"]
        self.supported_image_formats = [".jpg", ".jpeg", ".png", ".bmp", ".webp"]

    def validate_inputs(
        self,
        video_file: Optional[str],
        reference_audio_file: Optional[str],
        script_text: str,
        source_image_file: Optional[str] = None
    ) -> Tuple[bool, str]:
        """çµ±åˆå…¥åŠ›æ¤œè¨¼"""
        if not INTEGRATION_AVAILABLE:
            return False, "âŒ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"

        # åŸºæœ¬å…¥åŠ›æ¤œè¨¼
        if not video_file:
            return False, "âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        if not reference_audio_file:
            return False, "âŒ ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"

        if not script_text or not script_text.strip():
            return False, "âŒ ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"

        if len(script_text.strip()) < 5:
            return False, "âŒ ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™ï¼ˆ5æ–‡å­—ä»¥ä¸Šï¼‰"

        if len(script_text.strip()) > 500:
            return False, "âŒ ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ500æ–‡å­—ä»¥ä¸‹ï¼‰"

        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼æ¤œè¨¼
        video_ext = Path(video_file).suffix.lower()
        audio_ext = Path(reference_audio_file).suffix.lower()

        if video_ext not in self.supported_video_formats:
            return False, f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å‹•ç”»å½¢å¼: {video_ext}"

        if audio_ext not in self.supported_audio_formats:
            return False, f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„éŸ³å£°å½¢å¼: {audio_ext}"

        # ã‚½ãƒ¼ã‚¹ç”»åƒæ¤œè¨¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if source_image_file:
            if not self.facefusion or not self.facefusion.is_available():
                return False, "âŒ FaceFusionæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"

            image_ext = Path(source_image_file).suffix.lower()
            if image_ext not in self.supported_image_formats:
                return False, f"âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ç”»åƒå½¢å¼: {image_ext}"

        return True, "âœ… çµ±åˆå…¥åŠ›æ¤œè¨¼OK"

    def process_three_stage_pipeline(
        self,
        video_file,
        reference_audio_file,
        script_text,
        source_image_file,
        use_gfpgan,
        device,
        progress=gr.Progress()
    ):
        """
        3æ®µéšçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†

        Args:
            video_file: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«
            reference_audio_file: ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
            script_text: ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆ
            source_image_file: ã‚½ãƒ¼ã‚¹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            use_gfpgan: GFPGANä½¿ç”¨ãƒ•ãƒ©ã‚°
            device: å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹
            progress: Gradioé€²æ—è¡¨ç¤º

        Returns:
            Tuple: (å‡ºåŠ›å‹•ç”», ãƒ­ã‚°, çµ±è¨ˆæƒ…å ±)
        """
        try:
            if not INTEGRATION_AVAILABLE:
                return None, "âŒ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", None

            # å…¥åŠ›æ¤œè¨¼
            is_valid, message = self.validate_inputs(
                video_file, reference_audio_file, script_text, source_image_file
            )
            if not is_valid:
                return None, message, None

            # å…¨ä½“çµ±è¨ˆæƒ…å ±
            pipeline_start_time = time.time()
            total_stats = {}
            log_messages = []

            # Phase 1: SoVITSéŸ³å£°ç”Ÿæˆ
            progress(0.0, "ğŸµ Phase 1: SoVITSéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”Ÿæˆä¸­...")
            log_messages.append("=" * 50)
            log_messages.append("ğŸµ Phase 1: SoVITSéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”Ÿæˆé–‹å§‹")
            log_messages.append("=" * 50)

            def sovits_progress(value, desc):
                progress(value * 0.3, f"ğŸµ Phase 1: {desc}")

            try:
                audio_result = self.sovits_wav2lip.process_sovits_audio_generation(
                    reference_audio_file, script_text, device, sovits_progress
                )

                if not audio_result or not audio_result.get("success"):
                    error_msg = audio_result.get("message", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼") if audio_result else "éŸ³å£°ç”Ÿæˆå¤±æ•—"
                    log_messages.append(f"âŒ Phase 1å¤±æ•—: {error_msg}")
                    return None, "\n".join(log_messages), None

                generated_audio = audio_result["audio_path"]
                total_stats["phase1"] = audio_result.get("stats", {})
                log_messages.append(f"âœ… Phase 1å®Œäº†: {generated_audio}")

            except Exception as e:
                log_messages.append(f"âŒ Phase 1ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return None, "\n".join(log_messages), None

            # Phase 2: FaceFusioné¡”äº¤æ›ï¼ˆæ¡ä»¶ä»˜ãï¼‰
            current_video = video_file

            if source_image_file and self.facefusion.is_available():
                progress(0.3, "ğŸ­ Phase 2: FaceFusioné¡”äº¤æ›å‡¦ç†ä¸­...")
                log_messages.append("\n" + "=" * 50)
                log_messages.append("ğŸ­ Phase 2: FaceFusioné¡”äº¤æ›é–‹å§‹")
                log_messages.append("=" * 50)

                def facefusion_progress(value, desc):
                    progress(0.3 + value * 0.4, f"ğŸ­ Phase 2: {desc}")

                try:
                    success, swapped_video, ff_log, ff_stats = self.facefusion.process_face_swap(
                        source_image_file, video_file, facefusion_progress
                    )

                    if success and swapped_video:
                        current_video = swapped_video
                        total_stats["phase2"] = ff_stats
                        log_messages.append(f"âœ… Phase 2å®Œäº†: {swapped_video}")
                        log_messages.append(ff_log)

                        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        progress(0.7, "ğŸ§¹ Phase 2: ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
                        self.facefusion.cleanup_memory()

                    else:
                        log_messages.append(f"âŒ Phase 2å¤±æ•—: {ff_log}")
                        # FaceFusionå¤±æ•—æ™‚ã¯å…ƒå‹•ç”»ã§ç¶šè¡Œ
                        log_messages.append("âš ï¸ å…ƒå‹•ç”»ã§Phase 3ã«é€²è¡Œã—ã¾ã™")

                except Exception as e:
                    log_messages.append(f"âŒ Phase 2ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    log_messages.append("âš ï¸ å…ƒå‹•ç”»ã§Phase 3ã«é€²è¡Œã—ã¾ã™")

            else:
                log_messages.append("\nğŸ”„ Phase 2: FaceFusion ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚½ãƒ¼ã‚¹ç”»åƒãªã—ï¼‰")

            # Phase 3: Wav2Lipæœ€çµ‚å‡¦ç†
            progress(0.7, "ğŸ’‹ Phase 3: Wav2Lipãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‡¦ç†ä¸­...")
            log_messages.append("\n" + "=" * 50)
            log_messages.append("ğŸ’‹ Phase 3: Wav2Lipãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹")
            log_messages.append("=" * 50)

            def wav2lip_progress(value, desc):
                progress(0.7 + value * 0.25, f"ğŸ’‹ Phase 3: {desc}")

            try:
                final_result = self.sovits_wav2lip.process_wav2lip_lipsync(
                    current_video, generated_audio, use_gfpgan, device, wav2lip_progress
                )

                if not final_result or not final_result.get("success"):
                    error_msg = final_result.get("message", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼") if final_result else "ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å¤±æ•—"
                    log_messages.append(f"âŒ Phase 3å¤±æ•—: {error_msg}")
                    return None, "\n".join(log_messages), None

                final_video = final_result["video_path"]
                total_stats["phase3"] = final_result.get("stats", {})
                log_messages.append(f"âœ… Phase 3å®Œäº†: {final_video}")

            except Exception as e:
                log_messages.append(f"âŒ Phase 3ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return None, "\n".join(log_messages), None

            # æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            progress(0.95, "ğŸ§¹ æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
            gc.collect()

            # å…¨ä½“çµ±è¨ˆæƒ…å ±
            total_time = time.time() - pipeline_start_time
            total_stats["total_time"] = total_time
            total_stats["pipeline_stages"] = 2 if not source_image_file else 3

            # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            progress(1.0, "âœ… 3æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†!")
            log_messages.append("\n" + "=" * 50)
            log_messages.append(f"ğŸ‰ 3æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†: {total_time:.1f}ç§’")
            log_messages.append("=" * 50)

            return final_video, "\n".join(log_messages), total_stats

        except Exception as e:
            error_msg = f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
            return None, error_msg, None

    def create_interface(self):
        """Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ"""
        with gr.Blocks(
            title="SoVITS-FaceFusion-Wav2Lip çµ±åˆã‚·ã‚¹ãƒ†ãƒ ",
            theme=gr.themes.Soft(),
            css="""
            .gradio-container {max-width: 1200px !important}
            .progress-bar {background: linear-gradient(90deg, #ff6b6b, #4ecdc4, #45b7d1) !important}
            .stage-header {background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 10px; border-radius: 8px; margin: 10px 0;}
            .facefusion-optional {border: 2px dashed #ffa726; padding: 15px; border-radius: 8px; background: #fff3e0;}
            """
        ) as interface:

            # ãƒ˜ãƒƒãƒ€ãƒ¼
            gr.HTML("""
            <div style="text-align: center; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
                <h1>ğŸ­ğŸµğŸ’‹ SoVITS-FaceFusion-Wav2Lip çµ±åˆã‚·ã‚¹ãƒ†ãƒ </h1>
                <p>éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ç”Ÿæˆ â†’ é¡”äº¤æ› â†’ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®3æ®µéšçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</p>
            </div>
            """)

            with gr.Row():
                # å·¦å´ï¼šå…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                with gr.Column(scale=1):
                    gr.HTML('<div class="stage-header"><h3>ğŸ“ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«</h3></div>')

                    # åŸºæœ¬å…¥åŠ›ï¼ˆå¿…é ˆï¼‰
                    video_input = gr.File(
                        label="ğŸ¬ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¿…é ˆï¼‰- å¯¾å¿œå½¢å¼: MP4, AVI, MOV, MKV, WebM",
                        file_types=["video"]
                    )

                    reference_audio_input = gr.File(
                        label="ğŸ¤ ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ï¼ˆå¿…é ˆï¼‰- å¯¾å¿œå½¢å¼: MP3, WAV, M4A, AAC, FLAC",
                        file_types=["audio"]
                    )

                    script_input = gr.Textbox(
                        label="ğŸ“ ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¿…é ˆï¼‰",
                        placeholder="ç”Ÿæˆã—ãŸã„éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›...",
                        lines=3,
                        max_lines=5
                    )

                    # FaceFusion ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                    gr.HTML('<div class="stage-header"><h3>ğŸ­ FaceFusion ã‚ªãƒ—ã‚·ãƒ§ãƒ³</h3></div>')

                    with gr.Group(elem_classes=["facefusion-optional"]):
                        gr.HTML("""
                        <div style="text-align: center; margin-bottom: 10px;">
                            <strong>ğŸ­ é¡”äº¤æ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³</strong><br>
                            <small>ã‚½ãƒ¼ã‚¹ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨é¡”äº¤æ›å‡¦ç†ã‚’è¡Œã„ã¾ã™</small>
                        </div>
                        """)

                        source_image_input = gr.File(
                            label="ğŸ–¼ï¸ ã‚½ãƒ¼ã‚¹ç”»åƒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰- é¡”äº¤æ›ç”¨ã€‚ãªã—ã®å ´åˆã¯å…ƒå‹•ç”»ã®ã¾ã¾å‡¦ç†",
                            file_types=["image"]
                        )

                        facefusion_status = gr.HTML()

                    # å‡¦ç†è¨­å®š
                    gr.HTML('<div class="stage-header"><h3>âš™ï¸ å‡¦ç†è¨­å®š</h3></div>')

                    use_gfpgan = gr.Checkbox(
                        label="âœ¨ GFPGANé¡”è£œæ­£ï¼ˆæ¨å¥¨ï¼‰",
                        value=True
                    )

                    device = gr.Radio(
                        choices=["cuda", "cpu"],
                        value="cuda",
                        label="ğŸ’» å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹ - CUDAï¼ˆæ¨å¥¨ï¼‰ã¾ãŸã¯CPU"
                    )

                    # å®Ÿè¡Œãƒœã‚¿ãƒ³
                    process_btn = gr.Button(
                        "ğŸš€ 3æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ",
                        variant="primary",
                        size="lg"
                    )

                # å³å´ï¼šå‡ºåŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                with gr.Column(scale=1):
                    gr.HTML('<div class="stage-header"><h3>ğŸ“Š å‡¦ç†çŠ¶æ³ãƒ»çµæœ</h3></div>')

                    # é€²æ—è¡¨ç¤º
                    progress_bar = gr.Progress()

                    # çµæœè¡¨ç¤º
                    output_video = gr.Video(
                        label="ğŸ¬ æœ€çµ‚å‡ºåŠ›å‹•ç”»",
                        interactive=False
                    )

                    # ãƒ­ã‚°è¡¨ç¤º
                    log_output = gr.Textbox(
                        label="ğŸ“ å‡¦ç†ãƒ­ã‚°",
                        lines=15,
                        max_lines=20,
                        interactive=False,
                        show_copy_button=True
                    )

                    # çµ±è¨ˆæƒ…å ±
                    stats_output = gr.JSON(
                        label="ğŸ“Š å‡¦ç†çµ±è¨ˆ",
                        visible=False
                    )

            # FaceFusionåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
            def check_facefusion_status():
                if not INTEGRATION_AVAILABLE:
                    return "âŒ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
                elif not self.facefusion or not self.facefusion.is_available():
                    return "âŒ FaceFusionæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼‰"
                else:
                    return "âœ… FaceFusionæ©Ÿèƒ½åˆ©ç”¨å¯èƒ½"

            # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            interface.load(
                fn=check_facefusion_status,
                outputs=facefusion_status
            )

            process_btn.click(
                fn=self.process_three_stage_pipeline,
                inputs=[
                    video_input,
                    reference_audio_input,
                    script_input,
                    source_image_input,
                    use_gfpgan,
                    device
                ],
                outputs=[output_video, log_output, stats_output]
            )

        return interface

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ SoVITS-FaceFusion-Wav2Lip çµ±åˆã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...")

    app = ThreeStageIntegratedApp()
    interface = app.create_interface()

    print("ğŸ“ ã‚¢ã‚¯ã‚»ã‚¹å…ˆ: http://localhost:7865")

    interface.launch(
        server_name="0.0.0.0",
        server_port=7865,
        share=False
    )

if __name__ == "__main__":
    main()