#!/usr/bin/env python3
"""
Audio Silence Reducer
1ç§’ä»¥ä¸Šã®ç„¡éŸ³åŒºé–“ã‚’è‡ªå‹•çš„ã«1ç§’ã«çŸ­ç¸®ã™ã‚‹
"""

import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
from typing import Optional, Tuple


class AudioSilenceReducer:
    def __init__(self,
                 silence_threshold: float = 0.01,  # ç„¡éŸ³åˆ¤å®šã®é–¾å€¤
                 max_silence_duration: float = 1.0,  # æœ€å¤§ç„¡éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
                 min_silence_duration: float = 0.1,  # æœ€å°ç„¡éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
                 sample_rate: int = 22050):
        """
        Args:
            silence_threshold: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆ0-1ï¼‰
            max_silence_duration: æœ€å¤§ç„¡éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            min_silence_duration: æœ€å°ç„¡éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            sample_rate: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
        """
        self.silence_threshold = silence_threshold
        self.max_silence_duration = max_silence_duration
        self.min_silence_duration = min_silence_duration
        self.sample_rate = sample_rate

    def detect_silence_regions(self, audio: np.ndarray,
                             hop_length: int = 512) -> list:
        """
        ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡º

        Args:
            audio: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
            hop_length: ãƒ•ãƒ¬ãƒ¼ãƒ é–“éš”

        Returns:
            List[Tuple[int, int]]: ç„¡éŸ³åŒºé–“ã®ãƒªã‚¹ãƒˆï¼ˆé–‹å§‹ã‚µãƒ³ãƒ—ãƒ«, çµ‚äº†ã‚µãƒ³ãƒ—ãƒ«ï¼‰
        """
        # RMS ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
        rms = librosa.feature.rms(y=audio, hop_length=hop_length)[0]

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç§’ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ä¿‚æ•°
        frame_to_time = hop_length / self.sample_rate

        # ç„¡éŸ³åˆ¤å®š
        silence_frames = rms < self.silence_threshold

        # é€£ç¶šã™ã‚‹ç„¡éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        silence_regions = []
        start_frame = None

        for i, is_silence in enumerate(silence_frames):
            if is_silence and start_frame is None:
                start_frame = i
            elif not is_silence and start_frame is not None:
                # ç„¡éŸ³åŒºé–“çµ‚äº†
                duration = (i - start_frame) * frame_to_time
                if duration >= self.min_silence_duration:
                    start_sample = start_frame * hop_length
                    end_sample = i * hop_length
                    silence_regions.append((start_sample, end_sample))
                start_frame = None

        # æœ€å¾ŒãŒç„¡éŸ³ã§çµ‚ã‚ã‚‹å ´åˆ
        if start_frame is not None:
            duration = (len(silence_frames) - start_frame) * frame_to_time
            if duration >= self.min_silence_duration:
                start_sample = start_frame * hop_length
                end_sample = len(audio)
                silence_regions.append((start_sample, end_sample))

        return silence_regions

    def reduce_silence(self, audio: np.ndarray) -> np.ndarray:
        """
        1ç§’ä»¥ä¸Šã®ç„¡éŸ³åŒºé–“ã‚’1ç§’ã«çŸ­ç¸®

        Args:
            audio: å…¥åŠ›éŸ³å£°ãƒ‡ãƒ¼ã‚¿

        Returns:
            å‡¦ç†æ¸ˆã¿éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        """
        silence_regions = self.detect_silence_regions(audio)

        if not silence_regions:
            return audio

        # å‡¦ç†å¾Œã®éŸ³å£°ã‚’æ§‹ç¯‰
        processed_segments = []
        last_end = 0

        for start_sample, end_sample in silence_regions:
            # ç„¡éŸ³åŒºé–“å‰ã®éŸ³å£°ã‚’è¿½åŠ 
            if start_sample > last_end:
                processed_segments.append(audio[last_end:start_sample])

            # ç„¡éŸ³åŒºé–“ã®é•·ã•ã‚’è¨ˆç®—
            silence_duration = (end_sample - start_sample) / self.sample_rate

            if silence_duration > self.max_silence_duration:
                # 1ç§’ã«çŸ­ç¸®
                new_silence_samples = int(self.max_silence_duration * self.sample_rate)
                reduced_silence = np.zeros(new_silence_samples, dtype=audio.dtype)
                processed_segments.append(reduced_silence)
                print(f"ğŸ”‡ ç„¡éŸ³åŒºé–“çŸ­ç¸®: {silence_duration:.2f}ç§’ â†’ {self.max_silence_duration:.2f}ç§’")
            else:
                # ãã®ã¾ã¾ä¿æŒ
                processed_segments.append(audio[start_sample:end_sample])

            last_end = end_sample

        # æœ€å¾Œã®éŸ³å£°éƒ¨åˆ†ã‚’è¿½åŠ 
        if last_end < len(audio):
            processed_segments.append(audio[last_end:])

        if processed_segments:
            return np.concatenate(processed_segments)
        else:
            return audio

    def process_audio_file(self, input_path: str, output_path: str) -> Tuple[bool, str]:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†

        Args:
            input_path: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            Tuple[bool, str]: (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        """
        try:
            input_path = Path(input_path)
            output_path = Path(output_path)

            if not input_path.exists():
                return False, f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}"

            print(f"ğŸµ éŸ³å£°ç„¡éŸ³å‰Šæ¸›å‡¦ç†é–‹å§‹: {input_path}")

            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            audio, sr = librosa.load(str(input_path), sr=self.sample_rate)
            original_duration = len(audio) / sr

            print(f"ğŸ“Š å…ƒã®éŸ³å£°æ™‚é–“: {original_duration:.2f}ç§’")

            # ç„¡éŸ³å‰Šæ¸›å‡¦ç†
            processed_audio = self.reduce_silence(audio)
            processed_duration = len(processed_audio) / sr

            print(f"ğŸ“Š å‡¦ç†å¾ŒéŸ³å£°æ™‚é–“: {processed_duration:.2f}ç§’")
            time_saved = original_duration - processed_duration

            if time_saved > 0.1:  # 0.1ç§’ä»¥ä¸ŠçŸ­ç¸®ã•ã‚ŒãŸå ´åˆ
                print(f"â° çŸ­ç¸®æ™‚é–“: {time_saved:.2f}ç§’")

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # å‡¦ç†æ¸ˆã¿éŸ³å£°ã‚’ä¿å­˜
            sf.write(str(output_path), processed_audio, sr)

            return True, f"ç„¡éŸ³å‰Šæ¸›å®Œäº†: {time_saved:.2f}ç§’çŸ­ç¸®"

        except Exception as e:
            error_msg = f"éŸ³å£°ç„¡éŸ³å‰Šæ¸›ã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(f"âŒ {error_msg}")
            return False, error_msg

    def get_audio_info(self, audio_path: str) -> dict:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’å–å¾—

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            éŸ³å£°æƒ…å ±ã®è¾æ›¸
        """
        try:
            audio, sr = librosa.load(audio_path, sr=None)
            duration = len(audio) / sr

            # ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡º
            silence_regions = self.detect_silence_regions(audio)
            silence_count = len(silence_regions)

            total_silence_duration = 0
            long_silence_count = 0

            for start, end in silence_regions:
                silence_duration = (end - start) / sr
                total_silence_duration += silence_duration
                if silence_duration > self.max_silence_duration:
                    long_silence_count += 1

            return {
                "duration": duration,
                "sample_rate": sr,
                "silence_regions": silence_count,
                "total_silence_duration": total_silence_duration,
                "long_silence_count": long_silence_count,
                "potential_time_saving": max(0, total_silence_duration - (silence_count * self.max_silence_duration))
            }

        except Exception as e:
            return {"error": str(e)}


def reduce_audio_silence(input_path: str,
                        output_path: Optional[str] = None,
                        max_silence_duration: float = 1.0) -> Tuple[bool, str, str]:
    """
    ä¾¿åˆ©é–¢æ•°ï¼šéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç„¡éŸ³å‰Šæ¸›

    Args:
        input_path: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãï¼‰
        max_silence_duration: æœ€å¤§ç„¡éŸ³æ™‚é–“ï¼ˆç§’ï¼‰

    Returns:
        Tuple[bool, str, str]: (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
    """
    if output_path is None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¦ã€å¾Œã§å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã«ç½®ãæ›ãˆ
        input_path_obj = Path(input_path)
        output_path = str(input_path_obj.parent / f"{input_path_obj.stem}_reduced{input_path_obj.suffix}")

    reducer = AudioSilenceReducer(max_silence_duration=max_silence_duration)
    success, message = reducer.process_audio_file(input_path, output_path)

    if success and output_path != input_path:
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ãæ›ãˆ
        try:
            import shutil
            shutil.move(output_path, input_path)
            output_path = input_path
        except Exception as e:
            return False, f"ãƒ•ã‚¡ã‚¤ãƒ«ç½®ãæ›ãˆã‚¨ãƒ©ãƒ¼: {e}", output_path

    return success, message, output_path


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    import sys

    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ³•: python audio_silence_reducer.py <input_audio_file> [output_audio_file]")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None

    success, message, output_path = reduce_audio_silence(input_file, output_file)

    if success:
        print(f"âœ… {message}")
        print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    else:
        print(f"âŒ {message}")
        sys.exit(1)