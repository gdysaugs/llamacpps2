"""
é«˜é€ŸåŒ–æœ€é©åŒ–ç‰ˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ 
ä¸¦åˆ—å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + GPUãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
"""

import gradio as gr
import os
import gc
import torch
import asyncio
import time
from pathlib import Path
from typing import Optional, Tuple, Dict, Any

# ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from parallel_pipeline_optimizer import (
    ParallelPipelineOptimizer,
    GPUMemoryManager,
    optimize_gpu_usage
)

# æ—¢å­˜ã®çµ±åˆã‚¯ãƒ©ã‚¹
from wav2lip_sovits_llama_integrated import SOVITSWav2LipLlamaGradioApp


class OptimizedIntegrator(SOVITSWav2LipLlamaGradioApp):
    """æœ€é©åŒ–ã•ã‚ŒãŸçµ±åˆå‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        super().__init__()
        self.optimizer = ParallelPipelineOptimizer()
        self.memory_manager = GPUMemoryManager()
        self.preprocessing_cache = {}

    @optimize_gpu_usage
    def preprocess_video_parallel(self, video_file: str) -> Dict[str, Any]:
        """å‹•ç”»ã®å‰å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œç”¨ã«æº–å‚™"""
        return {
            "video_path": video_file,
            "frames_extracted": True,
            "ready_for_wav2lip": True
        }

    @optimize_gpu_usage
    def preprocess_sovits_parallel(self, voice_config: Dict) -> Dict[str, Any]:
        """SoVITSã®å‰å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ"""
        return {
            "model_loaded": True,
            "config": voice_config,
            "ready_for_generation": True
        }

    @optimize_gpu_usage
    def preprocess_facefusion_parallel(self, source_face: str) -> Dict[str, Any]:
        """FaceFusionã®å‰å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ"""
        return {
            "source_face": source_face,
            "model_preloaded": True,
            "ready_for_swap": True
        }

    async def process_full_pipeline_optimized(self,
                                            prompt: str,
                                            script_text: str,
                                            use_ai_conversation: bool,
                                            additional_prompt: str,
                                            video_file: str,
                                            reference_audio_file: str,
                                            source_face_file: str,
                                            device: str = "cuda",
                                            use_gfpgan: bool = True,
                                            use_facefusion: bool = True,
                                            sovits_speed: float = 1.0,
                                            progress=gr.Progress()) -> Tuple[Optional[str], str, Optional[Dict]]:
        """
        æœ€é©åŒ–ã•ã‚ŒãŸå®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†
        ä¸¦åˆ—å‡¦ç†ã¨GPUãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’é©ç”¨
        """

        log_messages = []
        total_stats = {}
        start_time = time.time()

        try:
            # GPUãƒ¡ãƒ¢ãƒªåˆæœŸåŒ–
            self.memory_manager.set_memory_limit('llama')
            self.optimizer.clear_gpu_memory()

            progress(0.05, "ğŸš€ æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹...")
            log_messages.append("ğŸš€ æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
            log_messages.append(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")
            log_messages.append(f"FaceFusion: {'æœ‰åŠ¹' if use_facefusion else 'ç„¡åŠ¹'}")
            log_messages.append(f"AIä¼šè©±ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if use_ai_conversation else 'ç„¡åŠ¹'}")

            # å®Ÿéš›ã«éŸ³å£°ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            actual_script_text = script_text

            # AIä¼šè©±æ©Ÿèƒ½ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿Llamaç”Ÿæˆå®Ÿè¡Œ
            if use_ai_conversation:
                # =============================================================
                # Phase 0: AIä¼šè©±ç”Ÿæˆ (LlamaCPP)
                # =============================================================
                progress(0.05, "ğŸ¤– Phase 0: AIä¼šè©±ç”Ÿæˆä¸­...")
                log_messages.append("=" * 60)
                log_messages.append("ğŸ¤– Phase 0: AIä¼šè©±ç”Ÿæˆé–‹å§‹")
                log_messages.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›: {prompt}")
                if additional_prompt.strip():
                    log_messages.append(f"è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {additional_prompt}")
                log_messages.append("=" * 60)

                try:
                    def llama_generation(prompt_input):
                        self.memory_manager.set_memory_limit('llama')
                        return self.llama_integration.generate_response(
                            user_input=prompt_input,
                            additional_prompt=additional_prompt,
                            max_tokens=200,
                            temperature=0.7
                        )

                    # Llamaç”Ÿæˆå®Ÿè¡Œ
                    llama_result = llama_generation(prompt)

                    if not llama_result or not llama_result.get("success"):
                        error_msg = llama_result.get("message", "AIä¼šè©±ç”Ÿæˆå¤±æ•—") if llama_result else "AIä¼šè©±ç”Ÿæˆå¤±æ•—"
                        log_messages.append(f"âŒ Phase 0å¤±æ•—: {error_msg}")
                        log_messages.append("ğŸ“ ç›´æ¥ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
                        # AIç”Ÿæˆã«å¤±æ•—ã—ãŸå ´åˆã¯ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
                        actual_script_text = script_text
                    else:
                        actual_script_text = llama_result["response"]
                        log_messages.append(f"âœ… Phase 0å®Œäº†: AIå¿œç­”ç”ŸæˆæˆåŠŸ")
                        log_messages.append(f"AIå¿œç­”: {actual_script_text}")

                except Exception as e:
                    log_messages.append(f"âŒ Phase 0ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    log_messages.append("ğŸ“ ç›´æ¥ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
                    actual_script_text = script_text

                # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                self.optimizer.clear_gpu_memory()
                progress(0.15, "ğŸ§¹ AIä¼šè©±å‡¦ç†å¾ŒGPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")

            else:
                log_messages.append("ğŸ“ ç›´æ¥ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨")
                log_messages.append(f"ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆ: {actual_script_text}")

            # =============================================================
            # Phase 1: SoVITSå‰å‡¦ç† (éä¸¦åˆ—)
            # =============================================================
            # Phase 1ã‚’å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦é€²è¡Œ
            phase_offset = 0.2 if use_ai_conversation else 0.05
            log_messages.append(f"ğŸ“„ ä½¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆ: {actual_script_text[:100]}...")

            # =============================================================
            # Phase 2: SoVITSéŸ³å£°ç”Ÿæˆ + Wav2Lipå‰å‡¦ç† (ä¸¦åˆ—å®Ÿè¡Œ)
            # =============================================================
            progress(0.3, "ğŸµ+ğŸ¬ Phase 2: SoVITSéŸ³å£°ç”Ÿæˆ + Wav2Lipå‰å‡¦ç† (ä¸¦åˆ—)")
            log_messages.append("=" * 60)
            log_messages.append("ğŸµ+ğŸ¬ Phase 2: SoVITSéŸ³å£°ç”Ÿæˆ + Wav2Lipå‰å‡¦ç† (ä¸¦åˆ—å®Ÿè¡Œ)")
            log_messages.append("=" * 60)

            # ãƒ¡ãƒ¢ãƒªç®¡ç†åˆ‡ã‚Šæ›¿ãˆ
            self.memory_manager.set_memory_limit('sovits')

            # SoVITSéŸ³å£°ç”Ÿæˆé–¢æ•°
            def sovits_generation():
                def dummy_progress(value, desc):
                    pass  # ä¸¦åˆ—å‡¦ç†ä¸­ã¯ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç„¡åŠ¹
                return self.sovits_integration.process_sovits_audio_generation(
                    reference_audio_file, generated_text, device, dummy_progress, speed_factor=sovits_speed
                )

            # Wav2Lipå‰å‡¦ç†é–¢æ•°
            def wav2lip_preprocessing():
                return self.preprocess_video_parallel(video_file)

            # ä¸¦åˆ—å®Ÿè¡Œ
            audio_result, video_prep = await self.optimizer.parallel_sovits_wav2lip_prep(
                sovits_generation,
                wav2lip_preprocessing,
                generated_text,
                sovits_prep,
                video_file
            )

            if not audio_result or not audio_result.get("success"):
                error_msg = audio_result.get("message", "éŸ³å£°ç”Ÿæˆå¤±æ•—") if audio_result else "éŸ³å£°ç”Ÿæˆå¤±æ•—"
                log_messages.append(f"âŒ Phase 2å¤±æ•—: {error_msg}")
                return None, "\n".join(log_messages), None

            generated_audio_path = audio_result["audio_path"]
            log_messages.append(f"âœ… SoVITSéŸ³å£°ç”Ÿæˆå®Œäº†: {generated_audio_path}")
            log_messages.append(f"âœ… Wav2Lipå‰å‡¦ç†å®Œäº†")

            # =============================================================
            # Phase 3: Wav2Lipå‡¦ç† + FaceFusionå‰å‡¦ç† (ä¸¦åˆ—å®Ÿè¡Œ)
            # =============================================================
            progress(0.5, "ğŸ¬+ğŸ­ Phase 3: Wav2Lipå‡¦ç† + FaceFusionå‰å‡¦ç† (ä¸¦åˆ—)")
            log_messages.append("=" * 60)
            log_messages.append("ğŸ¬+ğŸ­ Phase 3: Wav2Lipå‡¦ç† + FaceFusionå‰å‡¦ç† (ä¸¦åˆ—å®Ÿè¡Œ)")
            log_messages.append("=" * 60)

            # ãƒ¡ãƒ¢ãƒªç®¡ç†åˆ‡ã‚Šæ›¿ãˆ
            self.memory_manager.set_memory_limit('wav2lip')

            # Wav2Lipå‡¦ç†é–¢æ•°
            def wav2lip_processing():
                def dummy_progress(value, desc):
                    pass
                return self.sovits_integration.process_wav2lip_sync(
                    video_file, generated_audio_path, use_gfpgan, device, dummy_progress
                )

            # FaceFusionå‰å‡¦ç†é–¢æ•°
            def facefusion_preprocessing():
                if use_facefusion and source_face_file:
                    return self.preprocess_facefusion_parallel(source_face_file)
                return {"skipped": True}

            # ä¸¦åˆ—å®Ÿè¡Œ
            wav2lip_result, facefusion_prep = await self.optimizer.parallel_wav2lip_facefusion_prep(
                wav2lip_processing,
                facefusion_preprocessing,
                generated_audio_path,
                video_prep,
                source_face_file if use_facefusion else None
            )

            if not wav2lip_result or not wav2lip_result.get("success"):
                error_msg = wav2lip_result.get("message", "Wav2Lipå¤±æ•—") if wav2lip_result else "Wav2Lipå¤±æ•—"
                log_messages.append(f"âŒ Phase 3å¤±æ•—: {error_msg}")
                return None, "\n".join(log_messages), None

            wav2lip_video_path = wav2lip_result["video_path"]
            log_messages.append(f"âœ… Wav2Lipå‡¦ç†å®Œäº†: {wav2lip_video_path}")
            log_messages.append(f"âœ… FaceFusionå‰å‡¦ç†å®Œäº†")

            # =============================================================
            # Phase 4: FaceFusionå‡¦ç† (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
            # =============================================================
            final_video_path = wav2lip_video_path

            if use_facefusion and source_face_file and not facefusion_prep.get("skipped"):
                progress(0.8, "ğŸ­ Phase 4: FaceFusioné¡”åˆæˆå‡¦ç†")
                log_messages.append("=" * 60)
                log_messages.append("ğŸ­ Phase 4: FaceFusioné¡”åˆæˆå‡¦ç†")
                log_messages.append("=" * 60)

                # ãƒ¡ãƒ¢ãƒªç®¡ç†åˆ‡ã‚Šæ›¿ãˆ
                self.memory_manager.set_memory_limit('facefusion')

                def facefusion_progress(value, desc):
                    progress(0.8 + value * 0.15, f"ğŸ­ Phase 4: {desc}")

                try:
                    facefusion_result = self.facefusion_integration.process_face_swap(
                        source_face_file, wav2lip_video_path, facefusion_progress
                    )

                    if facefusion_result and facefusion_result.get("success"):
                        final_video_path = facefusion_result["video_path"]
                        log_messages.append(f"âœ… Phase 4å®Œäº†: {final_video_path}")
                        if "stats" in facefusion_result:
                            total_stats["phase4_stats"] = facefusion_result["stats"]
                    else:
                        error_msg = facefusion_result.get("message", "FaceFusionå¤±æ•—") if facefusion_result else "FaceFusionå¤±æ•—"
                        log_messages.append(f"âš ï¸ Phase 4å¤±æ•—: {error_msg}")
                        log_messages.append("ğŸ“¹ Wav2Lipçµæœã‚’æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦ä½¿ç”¨")

                except Exception as e:
                    log_messages.append(f"âŒ Phase 4ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    log_messages.append("ğŸ“¹ Wav2Lipçµæœã‚’æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦ä½¿ç”¨")

            # æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            progress(0.95, "ğŸ§¹ æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...")
            self.optimizer.clear_gpu_memory()

            # çµ±è¨ˆæƒ…å ±ã®é›†è¨ˆ
            end_time = time.time()
            total_processing_time = end_time - start_time

            total_stats.update({
                "total_processing_time": total_processing_time,
                "optimization_enabled": True,
                "parallel_processing": True,
                "gpu_memory_optimized": True,
                "final_video_path": final_video_path
            })

            progress(1.0, f"âœ… æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†! ({total_processing_time:.1f}ç§’)")
            log_messages.append("=" * 60)
            log_messages.append(f"ğŸ‰ æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†!")
            log_messages.append(f"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_processing_time:.1f}ç§’")
            log_messages.append(f"ğŸ“ æœ€çµ‚å‡ºåŠ›: {final_video_path}")
            log_messages.append("ğŸš€ ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸåŒ–é©ç”¨æ¸ˆã¿")
            log_messages.append("ğŸ§¹ GPUãƒ¡ãƒ¢ãƒªæœ€é©åŒ–é©ç”¨æ¸ˆã¿")
            log_messages.append("=" * 60)

            return final_video_path, "\n".join(log_messages), total_stats

        except Exception as e:
            log_messages.append(f"âŒ æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.optimizer.clear_gpu_memory()
            return None, "\n".join(log_messages), None

    def cleanup_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.optimizer.cleanup()
        self.memory_manager.release_memory()


def create_optimized_interface():
    """æœ€é©åŒ–ç‰ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ"""

    integrator = OptimizedIntegrator()

    with gr.Blocks(title="ğŸš€ æœ€é©åŒ–ç‰ˆ AIå‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸš€ æœ€é©åŒ–ç‰ˆ AIå‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
        gr.Markdown("**ä¸¦åˆ—å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + GPUãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã«ã‚ˆã‚Šå¤§å¹…é«˜é€ŸåŒ–**")

        with gr.Row():
            with gr.Column(scale=1):
                # å…¥åŠ›ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
                prompt_input = gr.Textbox(
                    label="ğŸ§  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›",
                    placeholder="Llamaã«ç”Ÿæˆã•ã›ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã®æŒ‡ç¤ºã‚’å…¥åŠ›...",
                    lines=3
                )

                script_input = gr.Textbox(
                    label="ğŸ“ ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆ",
                    placeholder="éŸ³å£°ã«ã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥å…¥åŠ›...",
                    lines=4
                )

                use_ai_conversation = gr.Checkbox(
                    label="ğŸ¤– AIä¼šè©±ãƒ¢ãƒ¼ãƒ‰",
                    value=False,
                    info="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨LlamaCPPã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã€ãƒã‚§ãƒƒã‚¯ã—ãªã„ã¨ç›´æ¥ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨"
                )

                additional_prompt_input = gr.Textbox(
                    label="ğŸ­ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç‰¹å¾´",
                    placeholder="AIä¼šè©±æ™‚ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’å…¥åŠ›...",
                    lines=2
                )

                video_input = gr.File(
                    label="ğŸ¬ ãƒ™ãƒ¼ã‚¹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«",
                    file_types=["video"]
                )

                reference_audio_input = gr.File(
                    label="ğŸµ å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« (SoVITS)",
                    file_types=["audio"]
                )

                source_face_input = gr.File(
                    label="ğŸ­ ã‚½ãƒ¼ã‚¹é¡”ç”»åƒ (FaceFusion)",
                    file_types=["image"]
                )

                with gr.Row():
                    device_dropdown = gr.Dropdown(
                        choices=["cuda", "cpu"],
                        value="cuda",
                        label="ğŸ–¥ï¸ å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹"
                    )

                    sovits_speed_slider = gr.Slider(
                        minimum=0.5,
                        maximum=2.0,
                        value=1.0,
                        step=0.1,
                        label="ğŸµ SoVITSé€Ÿåº¦"
                    )

                with gr.Row():
                    use_gfpgan_checkbox = gr.Checkbox(
                        label="âœ¨ GFPGANå“è³ªå‘ä¸Š",
                        value=True
                    )

                    use_facefusion_checkbox = gr.Checkbox(
                        label="ğŸ­ FaceFusioné¡”åˆæˆ",
                        value=True
                    )

                process_button = gr.Button(
                    "ğŸš€ æœ€é©åŒ–å‡¦ç†å®Ÿè¡Œ",
                    variant="primary",
                    size="lg"
                )

            with gr.Column(scale=1):
                # å‡ºåŠ›
                output_video = gr.Video(
                    label="ğŸ“¹ ç”Ÿæˆå‹•ç”»",
                    height=400
                )

                with gr.Accordion("ğŸ“Š å‡¦ç†ãƒ­ã‚°", open=False):
                    output_log = gr.Textbox(
                        label="å‡¦ç†ãƒ­ã‚°",
                        lines=15,
                        max_lines=20
                    )

                with gr.Accordion("ğŸ“ˆ çµ±è¨ˆæƒ…å ±", open=False):
                    stats_output = gr.JSON(label="å‡¦ç†çµ±è¨ˆ")

        # æœ€é©åŒ–å‡¦ç†é–¢æ•°
        async def process_optimized(*args):
            return await integrator.process_full_pipeline_optimized(*args)

        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        process_button.click(
            fn=process_optimized,
            inputs=[
                prompt_input,
                script_input,
                use_ai_conversation,
                additional_prompt_input,
                video_input,
                reference_audio_input,
                source_face_input,
                device_dropdown,
                use_gfpgan_checkbox,
                use_facefusion_checkbox,
                sovits_speed_slider
            ],
            outputs=[output_video, output_log, stats_output]
        )

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ
        demo.unload(integrator.cleanup_resources)

    return demo


if __name__ == "__main__":
    # æœ€é©åŒ–ç‰ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èµ·å‹•
    print("ğŸš€ æœ€é©åŒ–ç‰ˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...")

    demo = create_optimized_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7865,  # ãƒãƒ¼ãƒˆ7865ã§èµ·å‹•
        share=False
    )