#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPT-SoVITS æ¨è«–ãƒ•ã‚¡ã‚¤ãƒ« (gpt_sovits_envå°‚ç”¨)
GPUå¯¾å¿œãƒ»v4ãƒ¢ãƒ‡ãƒ«ãƒ»æ—¥æœ¬èªå¯¾å¿œ

ä½¿ç”¨æ–¹æ³•:
source gpt_sovits_env/bin/activate
python gpt_sovits_inference_env.py "ç”Ÿæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆ" output.wav

Requirements:
- gpt_sovits_envç’°å¢ƒã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆå¿…é ˆ
- models/gpt_sovits/gpt_sovits_model.ckpt
- models/gpt_sovits/pretrained_models/s2Gv4.pth
"""

import os
import sys
import argparse
import traceback
import logging
from pathlib import Path
import torch
import yaml
from typing import Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
PROJECT_ROOT = Path(__file__).parent.absolute()
MODELS_ROOT = PROJECT_ROOT / "models/gpt_sovits"
PRETRAINED_ROOT = MODELS_ROOT / "pretrained_models"

# ãƒ‘ã‚¹ã®è¨­å®š - ERes2NetV2ã®å ´æ‰€ã‚’è¿½åŠ 
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PRETRAINED_ROOT))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¿…è¦ãªä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®import
try:
    import numpy as np
    import torch
    import torchaudio
    import soundfile as sf
    from transformers import AutoModel, AutoTokenizer
    import librosa
    import json
    logger.info("âœ… åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†")
except ImportError as e:
    logger.error(f"åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    raise

# GPT-SoVITS modules import
try:
    from tools.i18n.i18n import I18nAuto
    from GPT_SoVITS.TTS_infer_pack.TTS import TTS, TTS_Config
    from GPT_SoVITS.TTS_infer_pack.text_segmentation_method import get_method_names
    logger.info("âœ… GPT-SoVITS ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†")
except ImportError as e:
    logger.error(f"GPT-SoVITSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    raise

class GPTSoVITSInferenceEnv:
    """
    GPT-SoVITSæ¨è«–ã‚¯ãƒ©ã‚¹ (gpt_sovits_envå°‚ç”¨)
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.project_root = PROJECT_ROOT
        self.models_root = MODELS_ROOT
        self.tts_pipeline = None
        self.tts_config = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        logger.info(f"ğŸš€ GPT-SoVITSæ¨è«–ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–")
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {self.project_root}")
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.models_root}")
        logger.info(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")

        self._initialize()

    def _create_config(self):
        """è¨­å®šã®ä½œæˆ"""
        # å‹•çš„è¨­å®šä½œæˆ
        config_data = {
            "custom": {
                "device": self.device,
                "is_half": self.device == "cuda",
                "version": "v4",
                "bert_base_path": str(PRETRAINED_ROOT / "chinese-roberta-wwm-ext-large"),
                "cnhuhbert_base_path": str(PRETRAINED_ROOT / "chinese-hubert-base"),
                "t2s_weights_path": str(MODELS_ROOT / "gpt_sovits_model.ckpt"),
                "vits_weights_path": str(PRETRAINED_ROOT / "s2Gv4.pth")
            }
        }

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        config_path = self.project_root / "tts_infer_env.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True)

        logger.info(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {config_path}")
        return config_path

    def _initialize(self):
        """è¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        try:
            # å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            gpt_model_path = MODELS_ROOT / "gpt_sovits_model.ckpt"
            vits_model_path = PRETRAINED_ROOT / "s2Gv4.pth"

            if not gpt_model_path.exists():
                raise FileNotFoundError(f"GPTãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {gpt_model_path}")
            if not vits_model_path.exists():
                raise FileNotFoundError(f"VITSãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vits_model_path}")

            logger.info(f"âœ… GPTãƒ¢ãƒ‡ãƒ«ç¢ºèª: {gpt_model_path}")
            logger.info(f"âœ… VITSãƒ¢ãƒ‡ãƒ«ç¢ºèª: {vits_model_path}")

            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
            config_path = self._create_config()

            # TTSè¨­å®šã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
            self.tts_config = TTS_Config(str(config_path), config_name="custom")

            logger.info(f"ãƒ‡ãƒã‚¤ã‚¹: {self.tts_config.device}")
            logger.info(f"Half precision: {self.tts_config.is_half}")
            logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {self.tts_config.version}")

            # TTSãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
            logger.info("ğŸ”„ TTSãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
            self.tts_pipeline = TTS(self.tts_config)
            logger.info("âœ… GPT-SoVITSåˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            logger.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(traceback.format_exc())
            raise

    def generate_audio(self,
                      text: str,
                      ref_audio_path: str = None,
                      prompt_text: str = None,
                      text_lang: str = "ja",
                      prompt_lang: str = "ja",
                      output_path: str = "output/generated.wav",
                      **kwargs) -> str:
        """
        éŸ³å£°ç”Ÿæˆ

        Args:
            text (str): ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            ref_audio_path (str): ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ‘ã‚¹
            prompt_text (str): ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆ
            text_lang (str): ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èª
            prompt_lang (str): ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨€èª
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            **kwargs: ãã®ä»–ã®TTSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        try:
            logger.info(f"ğŸ¤ éŸ³å£°ç”Ÿæˆé–‹å§‹: '{text[:50]}{'...' if len(text) > 50 else ''}'")

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã®è¨­å®š
            if ref_audio_path is None:
                # åˆ©ç”¨å¯èƒ½ãªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’æ¢ã™
                ref_candidates = [
                    "hajimemashite_reference.wav",
                    "hajimemashite_reference.mp3",
                    "baka_reference.wav",
                    "test_reference.wav",
                    "reference.wav"
                ]

                ref_audio_path = None
                for candidate in ref_candidates:
                    candidate_path = MODELS_ROOT / candidate
                    if candidate_path.exists():
                        ref_audio_path = str(candidate_path)
                        break

                if ref_audio_path is None:
                    raise FileNotFoundError("åˆ©ç”¨å¯èƒ½ãªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            if prompt_text is None:
                prompt_text = "ã¯ã˜ã‚ã¾ã—ã¦ã€ã“ã‚“ã«ã¡ã¯"

            # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã®è‡ªå‹•å¤‰æ›
            ref_audio_path = self._ensure_wav_format(ref_audio_path)
            logger.info(f"ğŸ“» ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°: {ref_audio_path}")

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # TTSå®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
            request_params = {
                "text": text,
                "text_lang": text_lang.lower(),
                "ref_audio_path": ref_audio_path,
                "prompt_text": prompt_text,
                "prompt_lang": prompt_lang.lower(),
                "top_k": kwargs.get("top_k", 15),
                "top_p": kwargs.get("top_p", 1.0),
                "temperature": kwargs.get("temperature", 1.0),
                "text_split_method": kwargs.get("text_split_method", "cut5"),
                "batch_size": kwargs.get("batch_size", 1),
                "speed_factor": kwargs.get("speed_factor", 1.0),
                "seed": kwargs.get("seed", -1),
                "parallel_infer": kwargs.get("parallel_infer", True),
                "repetition_penalty": kwargs.get("repetition_penalty", 1.35),
                "sample_steps": kwargs.get("sample_steps", 32),
                "super_sampling": kwargs.get("super_sampling", False),
                "return_fragment": False
            }

            logger.info(f"ğŸ“ TTS ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†")

            # TTSå®Ÿè¡Œ
            logger.info("ğŸ”„ éŸ³å£°ç”Ÿæˆå®Ÿè¡Œä¸­...")
            tts_generator = self.tts_pipeline.run(request_params)

            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            sr, audio_data = next(tts_generator)

            # WAVå½¢å¼ã§ä¿å­˜
            sf.write(str(output_path), audio_data, sr)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨æ™‚é–“ã®è¨ˆç®—
            file_size = output_path.stat().st_size / (1024 * 1024)  # MB
            duration = len(audio_data) / sr

            logger.info(f"âœ… éŸ³å£°ç”ŸæˆæˆåŠŸ: {output_path}")
            logger.info(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f}MB, å†ç”Ÿæ™‚é–“: {duration:.2f}ç§’")

            return str(output_path)

        except Exception as e:
            logger.error(f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(traceback.format_exc())
            raise

    def _ensure_wav_format(self, audio_path: str) -> str:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WAVå½¢å¼ã«å¤‰æ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        """
        audio_path = Path(audio_path)

        if not audio_path.exists():
            logger.warning(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {audio_path}")
            return str(audio_path)

        # æ—¢ã«WAVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if audio_path.suffix.lower() == ".wav":
            return str(audio_path)

        # WAVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
        wav_path = audio_path.with_suffix(".wav")

        # æ—¢ã«å¤‰æ›æ¸ˆã¿ã®å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if wav_path.exists():
            logger.info(f"âœ… å¤‰æ›æ¸ˆã¿WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {wav_path}")
            return str(wav_path)

        # ffmpegã‚’ä½¿ç”¨ã—ã¦WAVã«å¤‰æ›
        try:
            import subprocess
            logger.info(f"ğŸ”„ {audio_path.suffix}ã‚’WAVã«å¤‰æ›ä¸­: {audio_path} -> {wav_path}")

            cmd = [
                "ffmpeg", "-i", str(audio_path),
                "-ar", "22050", "-ac", "1", "-y", str(wav_path)
            ]

            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode == 0:
                logger.info(f"âœ… WAVå¤‰æ›å®Œäº†: {wav_path}")
                return str(wav_path)
            else:
                logger.warning(f"WAVå¤‰æ›å¤±æ•—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {audio_path}")
                return str(audio_path)

        except Exception as e:
            logger.warning(f"WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {str(e)}")
            return str(audio_path)


def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description="GPT-SoVITS æ¨è«–å®Ÿè¡Œ (envå°‚ç”¨)")
    parser.add_argument("text", help="ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ")
    parser.add_argument("output", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å")
    parser.add_argument("--ref_audio", help="ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ‘ã‚¹")
    parser.add_argument("--prompt_text", help="ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆ")
    parser.add_argument("--text_lang", default="ja", help="ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ja)")
    parser.add_argument("--prompt_lang", default="ja", help="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨€èª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ja)")

    args = parser.parse_args()

    try:
        # æ¨è«–ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        logger.info("ğŸš€ GPT-SoVITSæ¨è«–é–‹å§‹ (envç‰ˆ)")
        inference = GPTSoVITSInferenceEnv()

        # éŸ³å£°ç”Ÿæˆ
        result_path = inference.generate_audio(
            text=args.text,
            ref_audio_path=args.ref_audio,
            prompt_text=args.prompt_text,
            text_lang=args.text_lang,
            prompt_lang=args.prompt_lang,
            output_path=args.output
        )

        print(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {result_path}")

    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        sys.exit(1)


# Gradio/Wav2Lipçµ±åˆç”¨é–¢æ•°
def generate_audio_for_wav2lip(text: str,
                              output_filename: str = "generated_audio.wav",
                              **kwargs) -> Optional[str]:
    """
    Wav2Lipçµ±åˆç”¨ã®éŸ³å£°ç”Ÿæˆé–¢æ•°

    Args:
        text (str): ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        output_filename (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        **kwargs: ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        Optional[str]: ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    try:
        inference = GPTSoVITSInferenceEnv()
        output_path = PROJECT_ROOT / "output" / output_filename

        result_path = inference.generate_audio(
            text=text,
            output_path=str(output_path),
            **kwargs
        )

        return result_path
    except Exception as e:
        logger.error(f"Wav2Lipçµ±åˆç”¨éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


if __name__ == "__main__":
    main()