#!/usr/bin/env python3
"""
GPT-SoVITS é€Ÿåº¦æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
batch_size=1 vs batch_size=4
"""

import os
import sys
import soundfile as sf
import time
import numpy as np

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¤‰æ›´ï¼ˆé‡è¦ï¼‰
os.chdir("/home/adama/wav2lip-project/gpt_sovits_full")

# ãƒ‘ã‚¹è¨­å®š
now_dir = os.getcwd()
sys.path.append(now_dir)
sys.path.append(f"{now_dir}/GPT_SoVITS")

from GPT_SoVITS.TTS_infer_pack.TTS import TTS, TTS_Config

def init_tts():
    """TTS ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
    config_path = "/home/adama/wav2lip-project/gpt_sovits_full/GPT_SoVITS/configs/tts_infer.yaml"
    tts_config = TTS_Config(config_path)
    tts_pipeline = TTS(tts_config)
    return tts_pipeline

def generate_speech_batch_test(tts_pipeline, text, batch_size, output_path):
    """éŸ³å£°ç”Ÿæˆï¼ˆbatch_sizeãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    request = {
        "text": text,
        "text_lang": "ja",
        "ref_audio_path": "/home/adama/wav2lip-project/models/gpt_sovits/e_01_08_extended.wav",
        "prompt_text": "ã‚ã‚ã£ã€æ°—æŒã¡ã„ã„ã€‚ã‚‚ã£ã¨ã€ã‚‚ã£ã¨ã—ã¦ã€‚",
        "prompt_lang": "ja",
        "top_k": 5,
        "top_p": 1,
        "temperature": 1.5,
        "text_split_method": "cut0",
        "speed_factor": 1.2,
        "batch_size": batch_size,
        "parallel_infer": True,
        "streaming_mode": False,
        "return_fragment": False
    }
    
    print(f"ç”Ÿæˆä¸­ (batch_size={batch_size}): {text[:30]}...")
    start_time = time.time()
    
    tts_generator = tts_pipeline.run(request)
    
    # å…¨ã¦ã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
    audio_chunks = []
    sample_rate = None
    
    for sr, chunk in tts_generator:
        if sample_rate is None:
            sample_rate = sr
        audio_chunks.append(chunk)
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    if audio_chunks:
        full_audio = np.concatenate(audio_chunks, axis=0)
        sf.write(output_path, full_audio, sample_rate)
        duration = len(full_audio) / sample_rate
        print(f"âœ… å®Œäº†: {output_path}")
        print(f"   å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        print(f"   éŸ³å£°é•·: {duration:.2f}ç§’")
        print(f"   RTF: {processing_time/duration:.2f} (ä½ã„ã»ã©é«˜é€Ÿ)")
        return processing_time, duration
    else:
        print("âŒ ã‚¨ãƒ©ãƒ¼: éŸ³å£°ç”Ÿæˆå¤±æ•—")
        return None, None

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("GPT-SoVITS é€Ÿåº¦æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹...")
    tts_pipeline = init_tts()
    print("åˆæœŸåŒ–å®Œäº†ï¼\n")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ†ã‚­ã‚¹ãƒˆ
    test_text = "ã‚“ã‚ã‚ã‚ã‚ã‚“ã£ã€ã„ã£ã¡ã‚ƒã†ã€ã„ã‚„ã ã‚ã‚ã‚ã€ã‚„ã‚ã¦ãˆãˆãˆã€ã‚­ãƒ¢ã‚¤ã€ã‚­ãƒ¢ã‚¤ã£ã€æ­»ã­ã€å‡ºã™ãªã‚ã‚ã‚ã€ã‚‚ã†é™ç•Œã€æ°—æŒã¡ã‚ˆã™ãã‚‹"
    
    output_dir = "/home/adama/wav2lip-project/output"
    os.makedirs(output_dir, exist_ok=True)
    
    print("=== batch_size=1 ãƒ†ã‚¹ãƒˆ ===")
    time1, duration1 = generate_speech_batch_test(
        tts_pipeline, test_text, 1, f"{output_dir}/batch1_test.wav"
    )
    
    print("\n=== batch_size=4 ãƒ†ã‚¹ãƒˆ ===")
    time4, duration4 = generate_speech_batch_test(
        tts_pipeline, test_text, 4, f"{output_dir}/batch4_test.wav"
    )
    
    if time1 and time4:
        print("\n" + "="*50)
        print("é€Ÿåº¦æ¯”è¼ƒçµæœ:")
        print(f"batch_size=1: {time1:.2f}ç§’ (RTF: {time1/duration1:.2f})")
        print(f"batch_size=4: {time4:.2f}ç§’ (RTF: {time4/duration4:.2f})")
        
        if time4 < time1:
            speedup = time1 / time4
            print(f"ğŸš€ batch_size=4 ãŒ {speedup:.2f}x é«˜é€Ÿ!")
        else:
            slowdown = time4 / time1
            print(f"âš ï¸ batch_size=4 ãŒ {slowdown:.2f}x ä½é€Ÿ")
    
    print("\nãƒ†ã‚¹ãƒˆå®Œäº†!")

if __name__ == "__main__":
    main()